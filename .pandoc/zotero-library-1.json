[
  {"id":"bidermanLoRALearnsLess2024","abstract":"Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning method for large language models. LoRA saves memory by training only low rank perturbations to selected weight matrices. In this work, we compare the performance of LoRA and full finetuning on two target domains, programming and mathematics. We consider both the instruction finetuning (approximately 100K prompt-response pairs) and continued pretraining (20B unstructured tokens) data regimes. Our results show that, in the standard low-rank settings, LoRA substantially underperforms full finetuning. Nevertheless, LoRA better maintains the base model's performance on tasks outside the target domain. We show that LoRA mitigates forgetting more than common regularization techniques such as weight decay and dropout; it also helps maintain more diverse generations. Finally, we show that full finetuning learns perturbations with a rank that is 10-100X greater than typical LoRA configurations, possibly explaining some of the reported gaps. We conclude by proposing best practices for finetuning with LoRA.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Biderman","given":"Dan"},{"family":"Portes","given":"Jacob"},{"family":"Ortiz","given":"Jose Javier Gonzalez"},{"family":"Paul","given":"Mansheej"},{"family":"Greengard","given":"Philip"},{"family":"Jennings","given":"Connor"},{"family":"King","given":"Daniel"},{"family":"Havens","given":"Sam"},{"family":"Chiley","given":"Vitaliy"},{"family":"Frankle","given":"Jonathan"},{"family":"Blakeney","given":"Cody"},{"family":"Cunningham","given":"John P."}],"citation-key":"bidermanLoRALearnsLess2024","DOI":"10.48550/arXiv.2405.09673","issued":{"date-parts":[["2024",9,20]]},"number":"arXiv:2405.09673","publisher":"arXiv","source":"arXiv.org","title":"LoRA Learns Less and Forgets Less","type":"article","URL":"http://arxiv.org/abs/2405.09673"},
  {"id":"deepseek-aiDeepSeekV3TechnicalReport2024","abstract":"We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"DeepSeek-AI","given":""},{"family":"Liu","given":"Aixin"},{"family":"Feng","given":"Bei"},{"family":"Xue","given":"Bing"},{"family":"Wang","given":"Bingxuan"},{"family":"Wu","given":"Bochao"},{"family":"Lu","given":"Chengda"},{"family":"Zhao","given":"Chenggang"},{"family":"Deng","given":"Chengqi"},{"family":"Zhang","given":"Chenyu"},{"family":"Ruan","given":"Chong"},{"family":"Dai","given":"Damai"},{"family":"Guo","given":"Daya"},{"family":"Yang","given":"Dejian"},{"family":"Chen","given":"Deli"},{"family":"Ji","given":"Dongjie"},{"family":"Li","given":"Erhang"},{"family":"Lin","given":"Fangyun"},{"family":"Dai","given":"Fucong"},{"family":"Luo","given":"Fuli"},{"family":"Hao","given":"Guangbo"},{"family":"Chen","given":"Guanting"},{"family":"Li","given":"Guowei"},{"family":"Zhang","given":"H."},{"family":"Bao","given":"Han"},{"family":"Xu","given":"Hanwei"},{"family":"Wang","given":"Haocheng"},{"family":"Zhang","given":"Haowei"},{"family":"Ding","given":"Honghui"},{"family":"Xin","given":"Huajian"},{"family":"Gao","given":"Huazuo"},{"family":"Li","given":"Hui"},{"family":"Qu","given":"Hui"},{"family":"Cai","given":"J. L."},{"family":"Liang","given":"Jian"},{"family":"Guo","given":"Jianzhong"},{"family":"Ni","given":"Jiaqi"},{"family":"Li","given":"Jiashi"},{"family":"Wang","given":"Jiawei"},{"family":"Chen","given":"Jin"},{"family":"Chen","given":"Jingchang"},{"family":"Yuan","given":"Jingyang"},{"family":"Qiu","given":"Junjie"},{"family":"Li","given":"Junlong"},{"family":"Song","given":"Junxiao"},{"family":"Dong","given":"Kai"},{"family":"Hu","given":"Kai"},{"family":"Gao","given":"Kaige"},{"family":"Guan","given":"Kang"},{"family":"Huang","given":"Kexin"},{"family":"Yu","given":"Kuai"},{"family":"Wang","given":"Lean"},{"family":"Zhang","given":"Lecong"},{"family":"Xu","given":"Lei"},{"family":"Xia","given":"Leyi"},{"family":"Zhao","given":"Liang"},{"family":"Wang","given":"Litong"},{"family":"Zhang","given":"Liyue"},{"family":"Li","given":"Meng"},{"family":"Wang","given":"Miaojun"},{"family":"Zhang","given":"Mingchuan"},{"family":"Zhang","given":"Minghua"},{"family":"Tang","given":"Minghui"},{"family":"Li","given":"Mingming"},{"family":"Tian","given":"Ning"},{"family":"Huang","given":"Panpan"},{"family":"Wang","given":"Peiyi"},{"family":"Zhang","given":"Peng"},{"family":"Wang","given":"Qiancheng"},{"family":"Zhu","given":"Qihao"},{"family":"Chen","given":"Qinyu"},{"family":"Du","given":"Qiushi"},{"family":"Chen","given":"R. J."},{"family":"Jin","given":"R. L."},{"family":"Ge","given":"Ruiqi"},{"family":"Zhang","given":"Ruisong"},{"family":"Pan","given":"Ruizhe"},{"family":"Wang","given":"Runji"},{"family":"Xu","given":"Runxin"},{"family":"Zhang","given":"Ruoyu"},{"family":"Chen","given":"Ruyi"},{"family":"Li","given":"S. S."},{"family":"Lu","given":"Shanghao"},{"family":"Zhou","given":"Shangyan"},{"family":"Chen","given":"Shanhuang"},{"family":"Wu","given":"Shaoqing"},{"family":"Ye","given":"Shengfeng"},{"family":"Ye","given":"Shengfeng"},{"family":"Ma","given":"Shirong"},{"family":"Wang","given":"Shiyu"},{"family":"Zhou","given":"Shuang"},{"family":"Yu","given":"Shuiping"},{"family":"Zhou","given":"Shunfeng"},{"family":"Pan","given":"Shuting"},{"family":"Wang","given":"T."},{"family":"Yun","given":"Tao"},{"family":"Pei","given":"Tian"},{"family":"Sun","given":"Tianyu"},{"family":"Xiao","given":"W. L."},{"family":"Zeng","given":"Wangding"},{"family":"Zhao","given":"Wanjia"},{"family":"An","given":"Wei"},{"family":"Liu","given":"Wen"},{"family":"Liang","given":"Wenfeng"},{"family":"Gao","given":"Wenjun"},{"family":"Yu","given":"Wenqin"},{"family":"Zhang","given":"Wentao"},{"family":"Li","given":"X. Q."},{"family":"Jin","given":"Xiangyue"},{"family":"Wang","given":"Xianzu"},{"family":"Bi","given":"Xiao"},{"family":"Liu","given":"Xiaodong"},{"family":"Wang","given":"Xiaohan"},{"family":"Shen","given":"Xiaojin"},{"family":"Chen","given":"Xiaokang"},{"family":"Zhang","given":"Xiaokang"},{"family":"Chen","given":"Xiaosha"},{"family":"Nie","given":"Xiaotao"},{"family":"Sun","given":"Xiaowen"},{"family":"Wang","given":"Xiaoxiang"},{"family":"Cheng","given":"Xin"},{"family":"Liu","given":"Xin"},{"family":"Xie","given":"Xin"},{"family":"Liu","given":"Xingchao"},{"family":"Yu","given":"Xingkai"},{"family":"Song","given":"Xinnan"},{"family":"Shan","given":"Xinxia"},{"family":"Zhou","given":"Xinyi"},{"family":"Yang","given":"Xinyu"},{"family":"Li","given":"Xinyuan"},{"family":"Su","given":"Xuecheng"},{"family":"Lin","given":"Xuheng"},{"family":"Li","given":"Y. K."},{"family":"Wang","given":"Y. Q."},{"family":"Wei","given":"Y. X."},{"family":"Zhu","given":"Y. X."},{"family":"Zhang","given":"Yang"},{"family":"Xu","given":"Yanhong"},{"family":"Xu","given":"Yanhong"},{"family":"Huang","given":"Yanping"},{"family":"Li","given":"Yao"},{"family":"Zhao","given":"Yao"},{"family":"Sun","given":"Yaofeng"},{"family":"Li","given":"Yaohui"},{"family":"Wang","given":"Yaohui"},{"family":"Yu","given":"Yi"},{"family":"Zheng","given":"Yi"},{"family":"Zhang","given":"Yichao"},{"family":"Shi","given":"Yifan"},{"family":"Xiong","given":"Yiliang"},{"family":"He","given":"Ying"},{"family":"Tang","given":"Ying"},{"family":"Piao","given":"Yishi"},{"family":"Wang","given":"Yisong"},{"family":"Tan","given":"Yixuan"},{"family":"Ma","given":"Yiyang"},{"family":"Liu","given":"Yiyuan"},{"family":"Guo","given":"Yongqiang"},{"family":"Wu","given":"Yu"},{"family":"Ou","given":"Yuan"},{"family":"Zhu","given":"Yuchen"},{"family":"Wang","given":"Yuduan"},{"family":"Gong","given":"Yue"},{"family":"Zou","given":"Yuheng"},{"family":"He","given":"Yujia"},{"family":"Zha","given":"Yukun"},{"family":"Xiong","given":"Yunfan"},{"family":"Ma","given":"Yunxian"},{"family":"Yan","given":"Yuting"},{"family":"Luo","given":"Yuxiang"},{"family":"You","given":"Yuxiang"},{"family":"Liu","given":"Yuxuan"},{"family":"Zhou","given":"Yuyang"},{"family":"Wu","given":"Z. F."},{"family":"Ren","given":"Z. Z."},{"family":"Ren","given":"Zehui"},{"family":"Sha","given":"Zhangli"},{"family":"Fu","given":"Zhe"},{"family":"Xu","given":"Zhean"},{"family":"Huang","given":"Zhen"},{"family":"Zhang","given":"Zhen"},{"family":"Xie","given":"Zhenda"},{"family":"Zhang","given":"Zhengyan"},{"family":"Hao","given":"Zhewen"},{"family":"Gou","given":"Zhibin"},{"family":"Ma","given":"Zhicheng"},{"family":"Yan","given":"Zhigang"},{"family":"Shao","given":"Zhihong"},{"family":"Xu","given":"Zhipeng"},{"family":"Wu","given":"Zhiyu"},{"family":"Zhang","given":"Zhongyu"},{"family":"Li","given":"Zhuoshu"},{"family":"Gu","given":"Zihui"},{"family":"Zhu","given":"Zijia"},{"family":"Liu","given":"Zijun"},{"family":"Li","given":"Zilin"},{"family":"Xie","given":"Ziwei"},{"family":"Song","given":"Ziyang"},{"family":"Gao","given":"Ziyi"},{"family":"Pan","given":"Zizheng"}],"citation-key":"deepseek-aiDeepSeekV3TechnicalReport2024","DOI":"10.48550/arXiv.2412.19437","issued":{"date-parts":[["2024",12,27]]},"number":"arXiv:2412.19437","publisher":"arXiv","source":"arXiv.org","title":"DeepSeek-V3 Technical Report","type":"article","URL":"http://arxiv.org/abs/2412.19437"},
  {"id":"dongGeneralInstructionFollowingAlignment2024","abstract":"Following natural instructions is crucial for the effective application of Retrieval-Augmented Generation (RAG) systems. Despite recent advancements in Large Language Models (LLMs), research on assessing and improving instruction-following (IF) alignment within the RAG domain remains limited. To address this issue, we propose VIF-RAG, the first automated, scalable, and verifiable synthetic pipeline for instruction-following alignment in RAG systems. We start by manually crafting a minimal set of atomic instructions (<100) and developing combination rules to synthesize and verify complex instructions for a seed set. We then use supervised models for instruction rewriting while simultaneously generating code to automate the verification of instruction quality via a Python executor. Finally, we integrate these instructions with extensive RAG and general data samples, scaling up to a high-quality VIF-RAG-QA dataset (>100k) through automated processes. To further bridge the gap in instruction-following auto-evaluation for RAG systems, we introduce FollowRAG Benchmark, which includes approximately 3K test samples, covering 22 categories of general instruction constraints and four knowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG can seamlessly integrate with different RAG benchmarks. Using FollowRAG and eight widely-used IF and foundational abilities benchmarks for LLMs, we demonstrate that VIF-RAG markedly enhances LLM performance across a broad range of general instruction constraints while effectively leveraging its capabilities in RAG scenarios. Further analysis offers practical insights for achieving IF alignment in RAG systems. Our code and datasets are released at https://FollowRAG.github.io.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Dong","given":"Guanting"},{"family":"Song","given":"Xiaoshuai"},{"family":"Zhu","given":"Yutao"},{"family":"Qiao","given":"Runqi"},{"family":"Dou","given":"Zhicheng"},{"family":"Wen","given":"Ji-Rong"}],"citation-key":"dongGeneralInstructionFollowingAlignment2024","DOI":"10.48550/arXiv.2410.09584","issued":{"date-parts":[["2024",10,12]]},"number":"arXiv:2410.09584","publisher":"arXiv","source":"arXiv.org","title":"Toward General Instruction-Following Alignment for Retrieval-Augmented Generation","type":"article","URL":"http://arxiv.org/abs/2410.09584"},
  {"id":"esRAGASAutomatedEvaluation2023","abstract":"We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval and an LLM based generation module, and provide LLMs with knowledge from a reference textual database, which enables them to act as a natural language layer between a user and textual databases, reducing the risk of hallucinations. Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself. With RAGAs, we put forward a suite of metrics which can be used to evaluate these different dimensions \\textit{without having to rely on ground truth human annotations}. We posit that such a framework can crucially contribute to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Es","given":"Shahul"},{"family":"James","given":"Jithin"},{"family":"Espinosa-Anke","given":"Luis"},{"family":"Schockaert","given":"Steven"}],"citation-key":"esRAGASAutomatedEvaluation2023","DOI":"10.48550/arXiv.2309.15217","issued":{"date-parts":[["2023",9,26]]},"number":"arXiv:2309.15217","publisher":"arXiv","source":"arXiv.org","title":"RAGAS: Automated Evaluation of Retrieval Augmented Generation","title-short":"RAGAS","type":"article","URL":"http://arxiv.org/abs/2309.15217"},
  {"id":"grattafioriLlama3Herd2024","abstract":"Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Grattafiori","given":"Aaron"},{"family":"Dubey","given":"Abhimanyu"},{"family":"Jauhri","given":"Abhinav"},{"family":"Pandey","given":"Abhinav"},{"family":"Kadian","given":"Abhishek"},{"family":"Al-Dahle","given":"Ahmad"},{"family":"Letman","given":"Aiesha"},{"family":"Mathur","given":"Akhil"},{"family":"Schelten","given":"Alan"},{"family":"Vaughan","given":"Alex"},{"family":"Yang","given":"Amy"},{"family":"Fan","given":"Angela"},{"family":"Goyal","given":"Anirudh"},{"family":"Hartshorn","given":"Anthony"},{"family":"Yang","given":"Aobo"},{"family":"Mitra","given":"Archi"},{"family":"Sravankumar","given":"Archie"},{"family":"Korenev","given":"Artem"},{"family":"Hinsvark","given":"Arthur"},{"family":"Rao","given":"Arun"},{"family":"Zhang","given":"Aston"},{"family":"Rodriguez","given":"Aurelien"},{"family":"Gregerson","given":"Austen"},{"family":"Spataru","given":"Ava"},{"family":"Roziere","given":"Baptiste"},{"family":"Biron","given":"Bethany"},{"family":"Tang","given":"Binh"},{"family":"Chern","given":"Bobbie"},{"family":"Caucheteux","given":"Charlotte"},{"family":"Nayak","given":"Chaya"},{"family":"Bi","given":"Chloe"},{"family":"Marra","given":"Chris"},{"family":"McConnell","given":"Chris"},{"family":"Keller","given":"Christian"},{"family":"Touret","given":"Christophe"},{"family":"Wu","given":"Chunyang"},{"family":"Wong","given":"Corinne"},{"family":"Ferrer","given":"Cristian Canton"},{"family":"Nikolaidis","given":"Cyrus"},{"family":"Allonsius","given":"Damien"},{"family":"Song","given":"Daniel"},{"family":"Pintz","given":"Danielle"},{"family":"Livshits","given":"Danny"},{"family":"Wyatt","given":"Danny"},{"family":"Esiobu","given":"David"},{"family":"Choudhary","given":"Dhruv"},{"family":"Mahajan","given":"Dhruv"},{"family":"Garcia-Olano","given":"Diego"},{"family":"Perino","given":"Diego"},{"family":"Hupkes","given":"Dieuwke"},{"family":"Lakomkin","given":"Egor"},{"family":"AlBadawy","given":"Ehab"},{"family":"Lobanova","given":"Elina"},{"family":"Dinan","given":"Emily"},{"family":"Smith","given":"Eric Michael"},{"family":"Radenovic","given":"Filip"},{"family":"Guzmán","given":"Francisco"},{"family":"Zhang","given":"Frank"},{"family":"Synnaeve","given":"Gabriel"},{"family":"Lee","given":"Gabrielle"},{"family":"Anderson","given":"Georgia Lewis"},{"family":"Thattai","given":"Govind"},{"family":"Nail","given":"Graeme"},{"family":"Mialon","given":"Gregoire"},{"family":"Pang","given":"Guan"},{"family":"Cucurell","given":"Guillem"},{"family":"Nguyen","given":"Hailey"},{"family":"Korevaar","given":"Hannah"},{"family":"Xu","given":"Hu"},{"family":"Touvron","given":"Hugo"},{"family":"Zarov","given":"Iliyan"},{"family":"Ibarra","given":"Imanol Arrieta"},{"family":"Kloumann","given":"Isabel"},{"family":"Misra","given":"Ishan"},{"family":"Evtimov","given":"Ivan"},{"family":"Zhang","given":"Jack"},{"family":"Copet","given":"Jade"},{"family":"Lee","given":"Jaewon"},{"family":"Geffert","given":"Jan"},{"family":"Vranes","given":"Jana"},{"family":"Park","given":"Jason"},{"family":"Mahadeokar","given":"Jay"},{"family":"Shah","given":"Jeet"},{"family":"Linde","given":"Jelmer","dropping-particle":"van der"},{"family":"Billock","given":"Jennifer"},{"family":"Hong","given":"Jenny"},{"family":"Lee","given":"Jenya"},{"family":"Fu","given":"Jeremy"},{"family":"Chi","given":"Jianfeng"},{"family":"Huang","given":"Jianyu"},{"family":"Liu","given":"Jiawen"},{"family":"Wang","given":"Jie"},{"family":"Yu","given":"Jiecao"},{"family":"Bitton","given":"Joanna"},{"family":"Spisak","given":"Joe"},{"family":"Park","given":"Jongsoo"},{"family":"Rocca","given":"Joseph"},{"family":"Johnstun","given":"Joshua"},{"family":"Saxe","given":"Joshua"},{"family":"Jia","given":"Junteng"},{"family":"Alwala","given":"Kalyan Vasuden"},{"family":"Prasad","given":"Karthik"},{"family":"Upasani","given":"Kartikeya"},{"family":"Plawiak","given":"Kate"},{"family":"Li","given":"Ke"},{"family":"Heafield","given":"Kenneth"},{"family":"Stone","given":"Kevin"},{"family":"El-Arini","given":"Khalid"},{"family":"Iyer","given":"Krithika"},{"family":"Malik","given":"Kshitiz"},{"family":"Chiu","given":"Kuenley"},{"family":"Bhalla","given":"Kunal"},{"family":"Lakhotia","given":"Kushal"},{"family":"Rantala-Yeary","given":"Lauren"},{"family":"Maaten","given":"Laurens","dropping-particle":"van der"},{"family":"Chen","given":"Lawrence"},{"family":"Tan","given":"Liang"},{"family":"Jenkins","given":"Liz"},{"family":"Martin","given":"Louis"},{"family":"Madaan","given":"Lovish"},{"family":"Malo","given":"Lubo"},{"family":"Blecher","given":"Lukas"},{"family":"Landzaat","given":"Lukas"},{"family":"Oliveira","given":"Luke","dropping-particle":"de"},{"family":"Muzzi","given":"Madeline"},{"family":"Pasupuleti","given":"Mahesh"},{"family":"Singh","given":"Mannat"},{"family":"Paluri","given":"Manohar"},{"family":"Kardas","given":"Marcin"},{"family":"Tsimpoukelli","given":"Maria"},{"family":"Oldham","given":"Mathew"},{"family":"Rita","given":"Mathieu"},{"family":"Pavlova","given":"Maya"},{"family":"Kambadur","given":"Melanie"},{"family":"Lewis","given":"Mike"},{"family":"Si","given":"Min"},{"family":"Singh","given":"Mitesh Kumar"},{"family":"Hassan","given":"Mona"},{"family":"Goyal","given":"Naman"},{"family":"Torabi","given":"Narjes"},{"family":"Bashlykov","given":"Nikolay"},{"family":"Bogoychev","given":"Nikolay"},{"family":"Chatterji","given":"Niladri"},{"family":"Zhang","given":"Ning"},{"family":"Duchenne","given":"Olivier"},{"family":"Çelebi","given":"Onur"},{"family":"Alrassy","given":"Patrick"},{"family":"Zhang","given":"Pengchuan"},{"family":"Li","given":"Pengwei"},{"family":"Vasic","given":"Petar"},{"family":"Weng","given":"Peter"},{"family":"Bhargava","given":"Prajjwal"},{"family":"Dubal","given":"Pratik"},{"family":"Krishnan","given":"Praveen"},{"family":"Koura","given":"Punit Singh"},{"family":"Xu","given":"Puxin"},{"family":"He","given":"Qing"},{"family":"Dong","given":"Qingxiao"},{"family":"Srinivasan","given":"Ragavan"},{"family":"Ganapathy","given":"Raj"},{"family":"Calderer","given":"Ramon"},{"family":"Cabral","given":"Ricardo Silveira"},{"family":"Stojnic","given":"Robert"},{"family":"Raileanu","given":"Roberta"},{"family":"Maheswari","given":"Rohan"},{"family":"Girdhar","given":"Rohit"},{"family":"Patel","given":"Rohit"},{"family":"Sauvestre","given":"Romain"},{"family":"Polidoro","given":"Ronnie"},{"family":"Sumbaly","given":"Roshan"},{"family":"Taylor","given":"Ross"},{"family":"Silva","given":"Ruan"},{"family":"Hou","given":"Rui"},{"family":"Wang","given":"Rui"},{"family":"Hosseini","given":"Saghar"},{"family":"Chennabasappa","given":"Sahana"},{"family":"Singh","given":"Sanjay"},{"family":"Bell","given":"Sean"},{"family":"Kim","given":"Seohyun Sonia"},{"family":"Edunov","given":"Sergey"},{"family":"Nie","given":"Shaoliang"},{"family":"Narang","given":"Sharan"},{"family":"Raparthy","given":"Sharath"},{"family":"Shen","given":"Sheng"},{"family":"Wan","given":"Shengye"},{"family":"Bhosale","given":"Shruti"},{"family":"Zhang","given":"Shun"},{"family":"Vandenhende","given":"Simon"},{"family":"Batra","given":"Soumya"},{"family":"Whitman","given":"Spencer"},{"family":"Sootla","given":"Sten"},{"family":"Collot","given":"Stephane"},{"family":"Gururangan","given":"Suchin"},{"family":"Borodinsky","given":"Sydney"},{"family":"Herman","given":"Tamar"},{"family":"Fowler","given":"Tara"},{"family":"Sheasha","given":"Tarek"},{"family":"Georgiou","given":"Thomas"},{"family":"Scialom","given":"Thomas"},{"family":"Speckbacher","given":"Tobias"},{"family":"Mihaylov","given":"Todor"},{"family":"Xiao","given":"Tong"},{"family":"Karn","given":"Ujjwal"},{"family":"Goswami","given":"Vedanuj"},{"family":"Gupta","given":"Vibhor"},{"family":"Ramanathan","given":"Vignesh"},{"family":"Kerkez","given":"Viktor"},{"family":"Gonguet","given":"Vincent"},{"family":"Do","given":"Virginie"},{"family":"Vogeti","given":"Vish"},{"family":"Albiero","given":"Vítor"},{"family":"Petrovic","given":"Vladan"},{"family":"Chu","given":"Weiwei"},{"family":"Xiong","given":"Wenhan"},{"family":"Fu","given":"Wenyin"},{"family":"Meers","given":"Whitney"},{"family":"Martinet","given":"Xavier"},{"family":"Wang","given":"Xiaodong"},{"family":"Wang","given":"Xiaofang"},{"family":"Tan","given":"Xiaoqing Ellen"},{"family":"Xia","given":"Xide"},{"family":"Xie","given":"Xinfeng"},{"family":"Jia","given":"Xuchao"},{"family":"Wang","given":"Xuewei"},{"family":"Goldschlag","given":"Yaelle"},{"family":"Gaur","given":"Yashesh"},{"family":"Babaei","given":"Yasmine"},{"family":"Wen","given":"Yi"},{"family":"Song","given":"Yiwen"},{"family":"Zhang","given":"Yuchen"},{"family":"Li","given":"Yue"},{"family":"Mao","given":"Yuning"},{"family":"Coudert","given":"Zacharie Delpierre"},{"family":"Yan","given":"Zheng"},{"family":"Chen","given":"Zhengxing"},{"family":"Papakipos","given":"Zoe"},{"family":"Singh","given":"Aaditya"},{"family":"Srivastava","given":"Aayushi"},{"family":"Jain","given":"Abha"},{"family":"Kelsey","given":"Adam"},{"family":"Shajnfeld","given":"Adam"},{"family":"Gangidi","given":"Adithya"},{"family":"Victoria","given":"Adolfo"},{"family":"Goldstand","given":"Ahuva"},{"family":"Menon","given":"Ajay"},{"family":"Sharma","given":"Ajay"},{"family":"Boesenberg","given":"Alex"},{"family":"Baevski","given":"Alexei"},{"family":"Feinstein","given":"Allie"},{"family":"Kallet","given":"Amanda"},{"family":"Sangani","given":"Amit"},{"family":"Teo","given":"Amos"},{"family":"Yunus","given":"Anam"},{"family":"Lupu","given":"Andrei"},{"family":"Alvarado","given":"Andres"},{"family":"Caples","given":"Andrew"},{"family":"Gu","given":"Andrew"},{"family":"Ho","given":"Andrew"},{"family":"Poulton","given":"Andrew"},{"family":"Ryan","given":"Andrew"},{"family":"Ramchandani","given":"Ankit"},{"family":"Dong","given":"Annie"},{"family":"Franco","given":"Annie"},{"family":"Goyal","given":"Anuj"},{"family":"Saraf","given":"Aparajita"},{"family":"Chowdhury","given":"Arkabandhu"},{"family":"Gabriel","given":"Ashley"},{"family":"Bharambe","given":"Ashwin"},{"family":"Eisenman","given":"Assaf"},{"family":"Yazdan","given":"Azadeh"},{"family":"James","given":"Beau"},{"family":"Maurer","given":"Ben"},{"family":"Leonhardi","given":"Benjamin"},{"family":"Huang","given":"Bernie"},{"family":"Loyd","given":"Beth"},{"family":"Paola","given":"Beto De"},{"family":"Paranjape","given":"Bhargavi"},{"family":"Liu","given":"Bing"},{"family":"Wu","given":"Bo"},{"family":"Ni","given":"Boyu"},{"family":"Hancock","given":"Braden"},{"family":"Wasti","given":"Bram"},{"family":"Spence","given":"Brandon"},{"family":"Stojkovic","given":"Brani"},{"family":"Gamido","given":"Brian"},{"family":"Montalvo","given":"Britt"},{"family":"Parker","given":"Carl"},{"family":"Burton","given":"Carly"},{"family":"Mejia","given":"Catalina"},{"family":"Liu","given":"Ce"},{"family":"Wang","given":"Changhan"},{"family":"Kim","given":"Changkyu"},{"family":"Zhou","given":"Chao"},{"family":"Hu","given":"Chester"},{"family":"Chu","given":"Ching-Hsiang"},{"family":"Cai","given":"Chris"},{"family":"Tindal","given":"Chris"},{"family":"Feichtenhofer","given":"Christoph"},{"family":"Gao","given":"Cynthia"},{"family":"Civin","given":"Damon"},{"family":"Beaty","given":"Dana"},{"family":"Kreymer","given":"Daniel"},{"family":"Li","given":"Daniel"},{"family":"Adkins","given":"David"},{"family":"Xu","given":"David"},{"family":"Testuggine","given":"Davide"},{"family":"David","given":"Delia"},{"family":"Parikh","given":"Devi"},{"family":"Liskovich","given":"Diana"},{"family":"Foss","given":"Didem"},{"family":"Wang","given":"Dingkang"},{"family":"Le","given":"Duc"},{"family":"Holland","given":"Dustin"},{"family":"Dowling","given":"Edward"},{"family":"Jamil","given":"Eissa"},{"family":"Montgomery","given":"Elaine"},{"family":"Presani","given":"Eleonora"},{"family":"Hahn","given":"Emily"},{"family":"Wood","given":"Emily"},{"family":"Le","given":"Eric-Tuan"},{"family":"Brinkman","given":"Erik"},{"family":"Arcaute","given":"Esteban"},{"family":"Dunbar","given":"Evan"},{"family":"Smothers","given":"Evan"},{"family":"Sun","given":"Fei"},{"family":"Kreuk","given":"Felix"},{"family":"Tian","given":"Feng"},{"family":"Kokkinos","given":"Filippos"},{"family":"Ozgenel","given":"Firat"},{"family":"Caggioni","given":"Francesco"},{"family":"Kanayet","given":"Frank"},{"family":"Seide","given":"Frank"},{"family":"Florez","given":"Gabriela Medina"},{"family":"Schwarz","given":"Gabriella"},{"family":"Badeer","given":"Gada"},{"family":"Swee","given":"Georgia"},{"family":"Halpern","given":"Gil"},{"family":"Herman","given":"Grant"},{"family":"Sizov","given":"Grigory"},{"family":"Guangyi","given":""},{"family":"Zhang","given":""},{"family":"Lakshminarayanan","given":"Guna"},{"family":"Inan","given":"Hakan"},{"family":"Shojanazeri","given":"Hamid"},{"family":"Zou","given":"Han"},{"family":"Wang","given":"Hannah"},{"family":"Zha","given":"Hanwen"},{"family":"Habeeb","given":"Haroun"},{"family":"Rudolph","given":"Harrison"},{"family":"Suk","given":"Helen"},{"family":"Aspegren","given":"Henry"},{"family":"Goldman","given":"Hunter"},{"family":"Zhan","given":"Hongyuan"},{"family":"Damlaj","given":"Ibrahim"},{"family":"Molybog","given":"Igor"},{"family":"Tufanov","given":"Igor"},{"family":"Leontiadis","given":"Ilias"},{"family":"Veliche","given":"Irina-Elena"},{"family":"Gat","given":"Itai"},{"family":"Weissman","given":"Jake"},{"family":"Geboski","given":"James"},{"family":"Kohli","given":"James"},{"family":"Lam","given":"Janice"},{"family":"Asher","given":"Japhet"},{"family":"Gaya","given":"Jean-Baptiste"},{"family":"Marcus","given":"Jeff"},{"family":"Tang","given":"Jeff"},{"family":"Chan","given":"Jennifer"},{"family":"Zhen","given":"Jenny"},{"family":"Reizenstein","given":"Jeremy"},{"family":"Teboul","given":"Jeremy"},{"family":"Zhong","given":"Jessica"},{"family":"Jin","given":"Jian"},{"family":"Yang","given":"Jingyi"},{"family":"Cummings","given":"Joe"},{"family":"Carvill","given":"Jon"},{"family":"Shepard","given":"Jon"},{"family":"McPhie","given":"Jonathan"},{"family":"Torres","given":"Jonathan"},{"family":"Ginsburg","given":"Josh"},{"family":"Wang","given":"Junjie"},{"family":"Wu","given":"Kai"},{"family":"U","given":"Kam Hou"},{"family":"Saxena","given":"Karan"},{"family":"Khandelwal","given":"Kartikay"},{"family":"Zand","given":"Katayoun"},{"family":"Matosich","given":"Kathy"},{"family":"Veeraraghavan","given":"Kaushik"},{"family":"Michelena","given":"Kelly"},{"family":"Li","given":"Keqian"},{"family":"Jagadeesh","given":"Kiran"},{"family":"Huang","given":"Kun"},{"family":"Chawla","given":"Kunal"},{"family":"Huang","given":"Kyle"},{"family":"Chen","given":"Lailin"},{"family":"Garg","given":"Lakshya"},{"family":"A","given":"Lavender"},{"family":"Silva","given":"Leandro"},{"family":"Bell","given":"Lee"},{"family":"Zhang","given":"Lei"},{"family":"Guo","given":"Liangpeng"},{"family":"Yu","given":"Licheng"},{"family":"Moshkovich","given":"Liron"},{"family":"Wehrstedt","given":"Luca"},{"family":"Khabsa","given":"Madian"},{"family":"Avalani","given":"Manav"},{"family":"Bhatt","given":"Manish"},{"family":"Mankus","given":"Martynas"},{"family":"Hasson","given":"Matan"},{"family":"Lennie","given":"Matthew"},{"family":"Reso","given":"Matthias"},{"family":"Groshev","given":"Maxim"},{"family":"Naumov","given":"Maxim"},{"family":"Lathi","given":"Maya"},{"family":"Keneally","given":"Meghan"},{"family":"Liu","given":"Miao"},{"family":"Seltzer","given":"Michael L."},{"family":"Valko","given":"Michal"},{"family":"Restrepo","given":"Michelle"},{"family":"Patel","given":"Mihir"},{"family":"Vyatskov","given":"Mik"},{"family":"Samvelyan","given":"Mikayel"},{"family":"Clark","given":"Mike"},{"family":"Macey","given":"Mike"},{"family":"Wang","given":"Mike"},{"family":"Hermoso","given":"Miquel Jubert"},{"family":"Metanat","given":"Mo"},{"family":"Rastegari","given":"Mohammad"},{"family":"Bansal","given":"Munish"},{"family":"Santhanam","given":"Nandhini"},{"family":"Parks","given":"Natascha"},{"family":"White","given":"Natasha"},{"family":"Bawa","given":"Navyata"},{"family":"Singhal","given":"Nayan"},{"family":"Egebo","given":"Nick"},{"family":"Usunier","given":"Nicolas"},{"family":"Mehta","given":"Nikhil"},{"family":"Laptev","given":"Nikolay Pavlovich"},{"family":"Dong","given":"Ning"},{"family":"Cheng","given":"Norman"},{"family":"Chernoguz","given":"Oleg"},{"family":"Hart","given":"Olivia"},{"family":"Salpekar","given":"Omkar"},{"family":"Kalinli","given":"Ozlem"},{"family":"Kent","given":"Parkin"},{"family":"Parekh","given":"Parth"},{"family":"Saab","given":"Paul"},{"family":"Balaji","given":"Pavan"},{"family":"Rittner","given":"Pedro"},{"family":"Bontrager","given":"Philip"},{"family":"Roux","given":"Pierre"},{"family":"Dollar","given":"Piotr"},{"family":"Zvyagina","given":"Polina"},{"family":"Ratanchandani","given":"Prashant"},{"family":"Yuvraj","given":"Pritish"},{"family":"Liang","given":"Qian"},{"family":"Alao","given":"Rachad"},{"family":"Rodriguez","given":"Rachel"},{"family":"Ayub","given":"Rafi"},{"family":"Murthy","given":"Raghotham"},{"family":"Nayani","given":"Raghu"},{"family":"Mitra","given":"Rahul"},{"family":"Parthasarathy","given":"Rangaprabhu"},{"family":"Li","given":"Raymond"},{"family":"Hogan","given":"Rebekkah"},{"family":"Battey","given":"Robin"},{"family":"Wang","given":"Rocky"},{"family":"Howes","given":"Russ"},{"family":"Rinott","given":"Ruty"},{"family":"Mehta","given":"Sachin"},{"family":"Siby","given":"Sachin"},{"family":"Bondu","given":"Sai Jayesh"},{"family":"Datta","given":"Samyak"},{"family":"Chugh","given":"Sara"},{"family":"Hunt","given":"Sara"},{"family":"Dhillon","given":"Sargun"},{"family":"Sidorov","given":"Sasha"},{"family":"Pan","given":"Satadru"},{"family":"Mahajan","given":"Saurabh"},{"family":"Verma","given":"Saurabh"},{"family":"Yamamoto","given":"Seiji"},{"family":"Ramaswamy","given":"Sharadh"},{"family":"Lindsay","given":"Shaun"},{"family":"Lindsay","given":"Shaun"},{"family":"Feng","given":"Sheng"},{"family":"Lin","given":"Shenghao"},{"family":"Zha","given":"Shengxin Cindy"},{"family":"Patil","given":"Shishir"},{"family":"Shankar","given":"Shiva"},{"family":"Zhang","given":"Shuqiang"},{"family":"Zhang","given":"Shuqiang"},{"family":"Wang","given":"Sinong"},{"family":"Agarwal","given":"Sneha"},{"family":"Sajuyigbe","given":"Soji"},{"family":"Chintala","given":"Soumith"},{"family":"Max","given":"Stephanie"},{"family":"Chen","given":"Stephen"},{"family":"Kehoe","given":"Steve"},{"family":"Satterfield","given":"Steve"},{"family":"Govindaprasad","given":"Sudarshan"},{"family":"Gupta","given":"Sumit"},{"family":"Deng","given":"Summer"},{"family":"Cho","given":"Sungmin"},{"family":"Virk","given":"Sunny"},{"family":"Subramanian","given":"Suraj"},{"family":"Choudhury","given":"Sy"},{"family":"Goldman","given":"Sydney"},{"family":"Remez","given":"Tal"},{"family":"Glaser","given":"Tamar"},{"family":"Best","given":"Tamara"},{"family":"Koehler","given":"Thilo"},{"family":"Robinson","given":"Thomas"},{"family":"Li","given":"Tianhe"},{"family":"Zhang","given":"Tianjun"},{"family":"Matthews","given":"Tim"},{"family":"Chou","given":"Timothy"},{"family":"Shaked","given":"Tzook"},{"family":"Vontimitta","given":"Varun"},{"family":"Ajayi","given":"Victoria"},{"family":"Montanez","given":"Victoria"},{"family":"Mohan","given":"Vijai"},{"family":"Kumar","given":"Vinay Satish"},{"family":"Mangla","given":"Vishal"},{"family":"Ionescu","given":"Vlad"},{"family":"Poenaru","given":"Vlad"},{"family":"Mihailescu","given":"Vlad Tiberiu"},{"family":"Ivanov","given":"Vladimir"},{"family":"Li","given":"Wei"},{"family":"Wang","given":"Wenchen"},{"family":"Jiang","given":"Wenwen"},{"family":"Bouaziz","given":"Wes"},{"family":"Constable","given":"Will"},{"family":"Tang","given":"Xiaocheng"},{"family":"Wu","given":"Xiaojian"},{"family":"Wang","given":"Xiaolan"},{"family":"Wu","given":"Xilun"},{"family":"Gao","given":"Xinbo"},{"family":"Kleinman","given":"Yaniv"},{"family":"Chen","given":"Yanjun"},{"family":"Hu","given":"Ye"},{"family":"Jia","given":"Ye"},{"family":"Qi","given":"Ye"},{"family":"Li","given":"Yenda"},{"family":"Zhang","given":"Yilin"},{"family":"Zhang","given":"Ying"},{"family":"Adi","given":"Yossi"},{"family":"Nam","given":"Youngjin"},{"family":"Yu","given":""},{"family":"Wang","given":""},{"family":"Zhao","given":"Yu"},{"family":"Hao","given":"Yuchen"},{"family":"Qian","given":"Yundi"},{"family":"Li","given":"Yunlu"},{"family":"He","given":"Yuzi"},{"family":"Rait","given":"Zach"},{"family":"DeVito","given":"Zachary"},{"family":"Rosnbrick","given":"Zef"},{"family":"Wen","given":"Zhaoduo"},{"family":"Yang","given":"Zhenyu"},{"family":"Zhao","given":"Zhiwei"},{"family":"Ma","given":"Zhiyu"}],"citation-key":"grattafioriLlama3Herd2024","DOI":"10.48550/arXiv.2407.21783","issued":{"date-parts":[["2024",11,23]]},"number":"arXiv:2407.21783","publisher":"arXiv","source":"arXiv.org","title":"The Llama 3 Herd of Models","type":"article","URL":"http://arxiv.org/abs/2407.21783"},
  {"id":"haoTrainingLargeLanguage2024","abstract":"Large language models (LLMs) are restricted to reason in the \"language space\", where they typically express the reasoning process with a chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue that language space may not always be optimal for reasoning. For example, most word tokens are primarily for textual coherence and not essential for reasoning, while some critical tokens require complex planning and pose huge challenges to LLMs. To explore the potential of LLM reasoning in an unrestricted latent space instead of using natural language, we introduce a new paradigm Coconut (Chain of Continuous Thought). We utilize the last hidden state of the LLM as a representation of the reasoning state (termed \"continuous thought\"). Rather than decoding this into a word token, we feed it back to the LLM as the subsequent input embedding directly in the continuous space. Experiments show that Coconut can effectively augment the LLM on several reasoning tasks. This novel latent reasoning paradigm leads to emergent advanced reasoning patterns: the continuous thought can encode multiple alternative next reasoning steps, allowing the model to perform a breadth-first search (BFS) to solve the problem, rather than prematurely committing to a single deterministic path like CoT. Coconut outperforms CoT in certain logical reasoning tasks that require substantial backtracking during planning, with fewer thinking tokens during inference. These findings demonstrate the promise of latent reasoning and offer valuable insights for future research.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Hao","given":"Shibo"},{"family":"Sukhbaatar","given":"Sainbayar"},{"family":"Su","given":"DiJia"},{"family":"Li","given":"Xian"},{"family":"Hu","given":"Zhiting"},{"family":"Weston","given":"Jason"},{"family":"Tian","given":"Yuandong"}],"citation-key":"haoTrainingLargeLanguage2024","DOI":"10.48550/arXiv.2412.06769","issued":{"date-parts":[["2024",12,11]]},"number":"arXiv:2412.06769","publisher":"arXiv","source":"arXiv.org","title":"Training Large Language Models to Reason in a Continuous Latent Space","type":"article","URL":"http://arxiv.org/abs/2412.06769"},
  {"id":"heGIVEStructuredReasoning2024","abstract":"Existing retrieval-based reasoning approaches for large language models (LLMs) heavily rely on the density and quality of the non-parametric knowledge source to provide domain knowledge and explicit reasoning chain. However, inclusive knowledge sources are expensive and sometimes infeasible to build for scientific or corner domains. To tackle the challenges, we introduce Graph Inspired Veracity Extrapolation (GIVE), a novel reasoning framework that integrates the parametric and non-parametric memories to enhance both knowledge retrieval and faithful reasoning processes on very sparse knowledge graphs. By leveraging the external structured knowledge to inspire LLM to model the interconnections among relevant concepts, our method facilitates a more logical and step-wise reasoning approach akin to experts' problem-solving, rather than gold answer retrieval. Specifically, the framework prompts LLMs to decompose the query into crucial concepts and attributes, construct entity groups with relevant entities, and build an augmented reasoning chain by probing potential relationships among node pairs across these entity groups. Our method incorporates both factual and extrapolated linkages to enable comprehensive understanding and response generation. Extensive experiments on reasoning-intense benchmarks on biomedical and commonsense QA demonstrate the effectiveness of our proposed method. Specifically, GIVE enables GPT3.5-turbo to outperform advanced models like GPT4 without any additional training cost, thereby underscoring the efficacy of integrating structured information and internal reasoning ability of LLMs for tackling specialized tasks with limited external resources.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"He","given":"Jiashu"},{"family":"Ma","given":"Mingyu Derek"},{"family":"Fan","given":"Jinxuan"},{"family":"Roth","given":"Dan"},{"family":"Wang","given":"Wei"},{"family":"Ribeiro","given":"Alejandro"}],"citation-key":"heGIVEStructuredReasoning2024","DOI":"10.48550/arXiv.2410.08475","issued":{"date-parts":[["2024",10,11]]},"number":"arXiv:2410.08475","publisher":"arXiv","source":"arXiv.org","title":"GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation","title-short":"GIVE","type":"article","URL":"http://arxiv.org/abs/2410.08475"},
  {"id":"hortonKVPredictionImproved2024","abstract":"Inference with transformer-based language models begins with a prompt processing step. In this step, the model generates the first output token and stores the KV cache needed for future generation steps. This prompt processing step can be computationally expensive, taking 10s of seconds or more for billion-parameter models on edge devices when prompt lengths or batch sizes rise. This degrades user experience by introducing significant latency into the model's outputs. To reduce the time spent producing the first output (known as the ``time to first token'', or TTFT) of a pretrained model, we introduce a novel method called KV Prediction. In our method, a small auxiliary model is used to process the prompt and produce an approximation of the KV cache used by a base model. This approximated KV cache is then used with the base model for autoregressive generation without the need to query the auxiliary model again. We demonstrate that our method produces a pareto-optimal efficiency-accuracy trade-off when compared to baselines. On TriviaQA, we demonstrate relative accuracy improvements in the range of $15\\%-50\\%$ across a range of TTFT FLOPs budgets. We also demonstrate accuracy improvements of up to $30\\%$ on HumanEval python code completion at fixed TTFT FLOPs budgets. Additionally, we benchmark models on an Apple M2 Pro CPU and demonstrate that our improvement in FLOPs translates to a TTFT speedup on hardware. We release our code at https://github.com/apple/corenet/tree/main/projects/kv-prediction .","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Horton","given":"Maxwell"},{"family":"Cao","given":"Qingqing"},{"family":"Sun","given":"Chenfan"},{"family":"Jin","given":"Yanzi"},{"family":"Mehta","given":"Sachin"},{"family":"Rastegari","given":"Mohammad"},{"family":"Nabi","given":"Moin"}],"citation-key":"hortonKVPredictionImproved2024","DOI":"10.48550/arXiv.2410.08391","issued":{"date-parts":[["2024",10,10]]},"number":"arXiv:2410.08391","publisher":"arXiv","source":"arXiv.org","title":"KV Prediction for Improved Time to First Token","type":"article","URL":"http://arxiv.org/abs/2410.08391"},
  {"id":"houDoesRLHFScale2024","abstract":"This study explores the scaling properties of Reinforcement Learning from Human Feedback (RLHF) in Large Language Models (LLMs). Although RLHF is considered an important step in post-training of LLMs, its scaling potential is still largely unknown. We systematically analyze key components in the RLHF framework--model size, data composition, and inference budget--and their impacts on performance. Our findings show that increasing data diversity and volume improves reward model performance, helping process-supervision models scale better. For policy training, more response samples per prompt boost performance initially but quickly plateau. And larger reward models offer modest gains in policy training. In addition, larger policy models benefit less from RLHF with a fixed reward model. Overall, RLHF scales less efficiently than pretraining, with diminishing returns from additional computational resources. Based on these observations, we propose strategies to optimize RLHF performance within computational limits.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Hou","given":"Zhenyu"},{"family":"Du","given":"Pengfan"},{"family":"Niu","given":"Yilin"},{"family":"Du","given":"Zhengxiao"},{"family":"Zeng","given":"Aohan"},{"family":"Liu","given":"Xiao"},{"family":"Huang","given":"Minlie"},{"family":"Wang","given":"Hongning"},{"family":"Tang","given":"Jie"},{"family":"Dong","given":"Yuxiao"}],"citation-key":"houDoesRLHFScale2024","DOI":"10.48550/arXiv.2412.06000","issued":{"date-parts":[["2024",12,8]]},"number":"arXiv:2412.06000","publisher":"arXiv","source":"arXiv.org","title":"Does RLHF Scale? Exploring the Impacts From Data, Model, and Method","title-short":"Does RLHF Scale?","type":"article","URL":"http://arxiv.org/abs/2412.06000"},
  {"id":"ibrahimSimpleScalableStrategies2024","abstract":"Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by the final loss and the average score on several language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\\rightarrow$English) and a stronger distribution shift (English$\\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Ibrahim","given":"Adam"},{"family":"Thérien","given":"Benjamin"},{"family":"Gupta","given":"Kshitij"},{"family":"Richter","given":"Mats L."},{"family":"Anthony","given":"Quentin"},{"family":"Lesort","given":"Timothée"},{"family":"Belilovsky","given":"Eugene"},{"family":"Rish","given":"Irina"}],"citation-key":"ibrahimSimpleScalableStrategies2024","DOI":"10.48550/arXiv.2403.08763","issued":{"date-parts":[["2024",9,4]]},"number":"arXiv:2403.08763","publisher":"arXiv","source":"arXiv.org","title":"Simple and Scalable Strategies to Continually Pre-train Large Language Models","type":"article","URL":"http://arxiv.org/abs/2403.08763"},
  {"id":"jiangMixtralExperts2024","abstract":"We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Jiang","given":"Albert Q."},{"family":"Sablayrolles","given":"Alexandre"},{"family":"Roux","given":"Antoine"},{"family":"Mensch","given":"Arthur"},{"family":"Savary","given":"Blanche"},{"family":"Bamford","given":"Chris"},{"family":"Chaplot","given":"Devendra Singh"},{"family":"Casas","given":"Diego","dropping-particle":"de las"},{"family":"Hanna","given":"Emma Bou"},{"family":"Bressand","given":"Florian"},{"family":"Lengyel","given":"Gianna"},{"family":"Bour","given":"Guillaume"},{"family":"Lample","given":"Guillaume"},{"family":"Lavaud","given":"Lélio Renard"},{"family":"Saulnier","given":"Lucile"},{"family":"Lachaux","given":"Marie-Anne"},{"family":"Stock","given":"Pierre"},{"family":"Subramanian","given":"Sandeep"},{"family":"Yang","given":"Sophia"},{"family":"Antoniak","given":"Szymon"},{"family":"Scao","given":"Teven Le"},{"family":"Gervet","given":"Théophile"},{"family":"Lavril","given":"Thibaut"},{"family":"Wang","given":"Thomas"},{"family":"Lacroix","given":"Timothée"},{"family":"Sayed","given":"William El"}],"citation-key":"jiangMixtralExperts2024","DOI":"10.48550/arXiv.2401.04088","issued":{"date-parts":[["2024",1,8]]},"number":"arXiv:2401.04088","publisher":"arXiv","source":"arXiv.org","title":"Mixtral of Experts","type":"article","URL":"http://arxiv.org/abs/2401.04088"},
  {"id":"jinLongContextLLMsMeet2024","abstract":"Retrieval-augmented generation (RAG) empowers large language models (LLMs) to utilize external knowledge sources. The increasing capacity of LLMs to process longer input sequences opens up avenues for providing more retrieved information, to potentially enhance the quality of generated outputs. It is plausible to assume that a larger retrieval set would contain more relevant information (higher recall), that might result in improved performance. However, our empirical findings demonstrate that for many long-context LLMs, the quality of generated output initially improves first, but then subsequently declines as the number of retrieved passages increases. This paper investigates this phenomenon, identifying the detrimental impact of retrieved \"hard negatives\" as a key contributor. To mitigate this and enhance the robustness of long-context LLM-based RAG, we propose both training-free and training-based approaches. We first showcase the effectiveness of retrieval reordering as a simple yet powerful training-free optimization. Furthermore, we explore training-based methods, specifically RAG-specific implicit LLM fine-tuning and RAG-oriented fine-tuning with intermediate reasoning, demonstrating their capacity for substantial performance gains. Finally, we conduct a systematic analysis of design choices for these training-based methods, including data distribution, retriever selection, and training context length.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Jin","given":"Bowen"},{"family":"Yoon","given":"Jinsung"},{"family":"Han","given":"Jiawei"},{"family":"Arik","given":"Sercan O."}],"citation-key":"jinLongContextLLMsMeet2024","DOI":"10.48550/arXiv.2410.05983","issued":{"date-parts":[["2024",10,8]]},"number":"arXiv:2410.05983","publisher":"arXiv","source":"arXiv.org","title":"Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG","title-short":"Long-Context LLMs Meet RAG","type":"article","URL":"http://arxiv.org/abs/2410.05983"},
  {"id":"kurticGiveMeBF162024","abstract":"Despite the popularity of large language model (LLM) quantization for inference acceleration, significant uncertainty remains regarding the accuracy-performance trade-offs associated with various quantization formats. We present a comprehensive empirical study of quantized accuracy, evaluating popular quantization formats (FP8, INT8, INT4) across academic benchmarks and real-world tasks, on the entire Llama-3.1 model family. Additionally, our study examines the difference in text generated by quantized models versus their uncompressed counterparts. Beyond benchmarks, we also present a couple of quantization improvements which allowed us to obtain state-of-the-art accuracy recovery results. Our investigation, encompassing over 500,000 individual evaluations, yields several key findings: (1) FP8 weight and activation quantization (W8A8-FP) is lossless across all model scales, (2) INT8 weight and activation quantization (W8A8-INT), when properly tuned, incurs surprisingly low 1-3% accuracy degradation, and (3) INT4 weight-only quantization (W4A16-INT) is competitive with 8-bit integer weight and activation quantization. To address the question of the \"best\" format for a given deployment environment, we conduct inference performance analysis using the popular open-source vLLM framework on various GPU architectures. We find that W4A16 offers the best cost-efficiency for synchronous deployments, and for asynchronous deployment on mid-tier GPUs. At the same time, W8A8 formats excel in asynchronous \"continuous batching\" deployment of mid- and large-size models on high-end GPUs. Our results provide a set of practical guidelines for deploying quantized LLMs across scales and performance requirements.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Kurtic","given":"Eldar"},{"family":"Marques","given":"Alexandre"},{"family":"Pandit","given":"Shubhra"},{"family":"Kurtz","given":"Mark"},{"family":"Alistarh","given":"Dan"}],"citation-key":"kurticGiveMeBF162024","DOI":"10.48550/arXiv.2411.02355","issued":{"date-parts":[["2024",11,4]]},"number":"arXiv:2411.02355","publisher":"arXiv","source":"arXiv.org","title":"\"Give Me BF16 or Give Me Death\"? Accuracy-Performance Trade-Offs in LLM Quantization","title-short":"\"Give Me BF16 or Give Me Death\"?","type":"article","URL":"http://arxiv.org/abs/2411.02355"},
  {"id":"letoOptimalSearchRetrieval2024","abstract":"Retrieval-augmented generation (RAG) is a promising method for addressing some of the memory-related challenges associated with Large Language Models (LLMs). Two separate systems form the RAG pipeline, the retriever and the reader, and the impact of each on downstream task performance is not well-understood. Here, we work towards the goal of understanding how retrievers can be optimized for RAG pipelines for common tasks such as Question Answering (QA). We conduct experiments focused on the relationship between retrieval and RAG performance on QA and attributed QA and unveil a number of insights useful to practitioners developing high-performance RAG pipelines. For example, lowering search accuracy has minor implications for RAG performance while potentially increasing retrieval speed and memory efficiency.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Leto","given":"Alexandria"},{"family":"Aguerrebere","given":"Cecilia"},{"family":"Bhati","given":"Ishwar"},{"family":"Willke","given":"Ted"},{"family":"Tepper","given":"Mariano"},{"family":"Vo","given":"Vy Ai"}],"citation-key":"letoOptimalSearchRetrieval2024","DOI":"10.48550/arXiv.2411.07396","issued":{"date-parts":[["2024",11,11]]},"number":"arXiv:2411.07396","publisher":"arXiv","source":"arXiv.org","title":"Toward Optimal Search and Retrieval for RAG","type":"article","URL":"http://arxiv.org/abs/2411.07396"},
  {"id":"liangKAGBoostingLLMs2024","abstract":"The recently developed retrieval-augmented generation (RAG) technology has enabled the efficient construction of domain-specific applications. However, it also has limitations, including the gap between vector similarity and the relevance of knowledge reasoning, as well as insensitivity to knowledge logic, such as numerical values, temporal relations, expert rules, and others, which hinder the effectiveness of professional knowledge services. In this work, we introduce a professional domain knowledge service framework called Knowledge Augmented Generation (KAG). KAG is designed to address the aforementioned challenges with the motivation of making full use of the advantages of knowledge graph(KG) and vector retrieval, and to improve generation and reasoning performance by bidirectionally enhancing large language models (LLMs) and KGs through five key aspects: (1) LLM-friendly knowledge representation, (2) mutual-indexing between knowledge graphs and original chunks, (3) logical-form-guided hybrid reasoning engine, (4) knowledge alignment with semantic reasoning, and (5) model capability enhancement for KAG. We compared KAG with existing RAG methods in multihop question answering and found that it significantly outperforms state-of-theart methods, achieving a relative improvement of 19.6% on 2wiki and 33.5% on hotpotQA in terms of F1 score. We have successfully applied KAG to two professional knowledge Q&A tasks of Ant Group, including E-Government Q&A and E-Health Q&A, achieving significant improvement in professionalism compared to RAG methods.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Liang","given":"Lei"},{"family":"Sun","given":"Mengshu"},{"family":"Gui","given":"Zhengke"},{"family":"Zhu","given":"Zhongshu"},{"family":"Jiang","given":"Zhouyu"},{"family":"Zhong","given":"Ling"},{"family":"Qu","given":"Yuan"},{"family":"Zhao","given":"Peilong"},{"family":"Bo","given":"Zhongpu"},{"family":"Yang","given":"Jin"},{"family":"Xiong","given":"Huaidong"},{"family":"Yuan","given":"Lin"},{"family":"Xu","given":"Jun"},{"family":"Wang","given":"Zaoyang"},{"family":"Zhang","given":"Zhiqiang"},{"family":"Zhang","given":"Wen"},{"family":"Chen","given":"Huajun"},{"family":"Chen","given":"Wenguang"},{"family":"Zhou","given":"Jun"}],"citation-key":"liangKAGBoostingLLMs2024","DOI":"10.48550/arXiv.2409.13731","issued":{"date-parts":[["2024",9,26]]},"number":"arXiv:2409.13731","publisher":"arXiv","source":"arXiv.org","title":"KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation","title-short":"KAG","type":"article","URL":"http://arxiv.org/abs/2409.13731"},
  {"id":"liLLMsasJudgesComprehensiveSurvey2024","abstract":"The rapid advancement of Large Language Models (LLMs) has driven their expanding application across various fields. One of the most promising applications is their role as evaluators based on natural language responses, referred to as ''LLMs-as-judges''. This framework has attracted growing attention from both academia and industry due to their excellent effectiveness, ability to generalize across tasks, and interpretability in the form of natural language. This paper presents a comprehensive survey of the LLMs-as-judges paradigm from five key perspectives: Functionality, Methodology, Applications, Meta-evaluation, and Limitations. We begin by providing a systematic definition of LLMs-as-Judges and introduce their functionality (Why use LLM judges?). Then we address methodology to construct an evaluation system with LLMs (How to use LLM judges?). Additionally, we investigate the potential domains for their application (Where to use LLM judges?) and discuss methods for evaluating them in various contexts (How to evaluate LLM judges?). Finally, we provide a detailed analysis of the limitations of LLM judges and discuss potential future directions. Through a structured and comprehensive analysis, we aim aims to provide insights on the development and application of LLMs-as-judges in both research and practice. We will continue to maintain the relevant resource list at https://github.com/CSHaitao/Awesome-LLMs-as-Judges.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Li","given":"Haitao"},{"family":"Dong","given":"Qian"},{"family":"Chen","given":"Junjie"},{"family":"Su","given":"Huixue"},{"family":"Zhou","given":"Yujia"},{"family":"Ai","given":"Qingyao"},{"family":"Ye","given":"Ziyi"},{"family":"Liu","given":"Yiqun"}],"citation-key":"liLLMsasJudgesComprehensiveSurvey2024","DOI":"10.48550/arXiv.2412.05579","issued":{"date-parts":[["2024",12,10]]},"number":"arXiv:2412.05579","publisher":"arXiv","source":"arXiv.org","title":"LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods","title-short":"LLMs-as-Judges","type":"article","URL":"http://arxiv.org/abs/2412.05579"},
  {"id":"liuDoRAWeightDecomposedLowRank2024","abstract":"Among the widely used parameter-efficient fine-tuning (PEFT) methods, LoRA and its variants have gained considerable popularity because of avoiding additional inference costs. However, there still often exists an accuracy gap between these methods and full fine-tuning (FT). In this work, we first introduce a novel weight decomposition analysis to investigate the inherent differences between FT and LoRA. Aiming to resemble the learning capacity of FT from the findings, we propose Weight-Decomposed Low-Rank Adaptation (DoRA). DoRA decomposes the pre-trained weight into two components, magnitude and direction, for fine-tuning, specifically employing LoRA for directional updates to efficiently minimize the number of trainable parameters. By employing \\ours, we enhance both the learning capacity and training stability of LoRA while avoiding any additional inference overhead. \\ours~consistently outperforms LoRA on fine-tuning LLaMA, LLaVA, and VL-BART on various downstream tasks, such as commonsense reasoning, visual instruction tuning, and image/video-text understanding. Code is available at https://github.com/NVlabs/DoRA.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Liu","given":"Shih-Yang"},{"family":"Wang","given":"Chien-Yi"},{"family":"Yin","given":"Hongxu"},{"family":"Molchanov","given":"Pavlo"},{"family":"Wang","given":"Yu-Chiang Frank"},{"family":"Cheng","given":"Kwang-Ting"},{"family":"Chen","given":"Min-Hung"}],"citation-key":"liuDoRAWeightDecomposedLowRank2024","DOI":"10.48550/arXiv.2402.09353","issued":{"date-parts":[["2024",7,9]]},"number":"arXiv:2402.09353","publisher":"arXiv","source":"arXiv.org","title":"DoRA: Weight-Decomposed Low-Rank Adaptation","title-short":"DoRA","type":"article","URL":"http://arxiv.org/abs/2402.09353"},
  {"id":"millerAddingErrorBars2024","abstract":"Evaluations are critical for understanding the capabilities of large language models (LLMs). Fundamentally, evaluations are experiments; but the literature on evaluations has largely ignored the literature from other sciences on experiment analysis and planning. This article shows researchers with some training in statistics how to think about and analyze data from language model evaluations. Conceptualizing evaluation questions as having been drawn from an unseen super-population, we present formulas for analyzing evaluation data, measuring differences between two models, and planning an evaluation experiment. We make a number of specific recommendations for running language model evaluations and reporting experiment results in a way that minimizes statistical noise and maximizes informativeness.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Miller","given":"Evan"}],"citation-key":"millerAddingErrorBars2024","DOI":"10.48550/arXiv.2411.00640","issued":{"date-parts":[["2024",11,1]]},"number":"arXiv:2411.00640","publisher":"arXiv","source":"arXiv.org","title":"Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations","title-short":"Adding Error Bars to Evals","type":"article","URL":"http://arxiv.org/abs/2411.00640"},
  {"id":"muennighoffMTEBMassiveText2023","abstract":"Text embeddings are commonly evaluated on a small set of datasets from a single task not covering their possible applications to other tasks. It is unclear whether state-of-the-art embeddings on semantic textual similarity (STS) can be equally well applied to other tasks like clustering or reranking. This makes progress in the field difficult to track, as various models are constantly being proposed without proper evaluation. To solve this problem, we introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on MTEB, we establish the most comprehensive benchmark of text embeddings to date. We find that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks. MTEB comes with open-source code and a public leaderboard at https://github.com/embeddings-benchmark/mteb.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Muennighoff","given":"Niklas"},{"family":"Tazi","given":"Nouamane"},{"family":"Magne","given":"Loïc"},{"family":"Reimers","given":"Nils"}],"citation-key":"muennighoffMTEBMassiveText2023","DOI":"10.48550/arXiv.2210.07316","issued":{"date-parts":[["2023",3,19]]},"number":"arXiv:2210.07316","publisher":"arXiv","source":"arXiv.org","title":"MTEB: Massive Text Embedding Benchmark","title-short":"MTEB","type":"article","URL":"http://arxiv.org/abs/2210.07316"},
  {"id":"murphyReinforcementLearningOverview2024","abstract":"This manuscript gives a big-picture, up-to-date overview of the field of (deep) reinforcement learning and sequential decision making, covering value-based RL, policy-gradient methods, model-based methods, and various other topics (including a very brief discussion of RL+LLMs).","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Murphy","given":"Kevin"}],"citation-key":"murphyReinforcementLearningOverview2024","DOI":"10.48550/arXiv.2412.05265","issued":{"date-parts":[["2024",12,6]]},"number":"arXiv:2412.05265","publisher":"arXiv","source":"arXiv.org","title":"Reinforcement Learning: An Overview","title-short":"Reinforcement Learning","type":"article","URL":"http://arxiv.org/abs/2412.05265"},
  {"id":"nussbaumNomicEmbedTraining2024","abstract":"This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on short and long-context tasks. We release the training code and model weights under an Apache 2 license. In contrast with other open-source models, we release a training data loader with 235 million curated text pairs that allows for the full replication of nomic-embed-text-v1. You can find code and data to replicate the model at https://github.com/nomic-ai/contrastors","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Nussbaum","given":"Zach"},{"family":"Morris","given":"John X."},{"family":"Duderstadt","given":"Brandon"},{"family":"Mulyar","given":"Andriy"}],"citation-key":"nussbaumNomicEmbedTraining2024","DOI":"10.48550/arXiv.2402.01613","issued":{"date-parts":[["2024",2,2]]},"number":"arXiv:2402.01613","publisher":"arXiv","source":"arXiv.org","title":"Nomic Embed: Training a Reproducible Long Context Text Embedder","title-short":"Nomic Embed","type":"article","URL":"http://arxiv.org/abs/2402.01613"},
  {"id":"ouyangLowBitQuantizationFavors2024","abstract":"We reveal that low-bit quantization favors undertrained large language models (LLMs) by observing that models with larger sizes or fewer training tokens experience less quantization-induced degradation (QiD) when applying low-bit quantization, whereas smaller models with extensive training tokens suffer significant QiD. To gain deeper insights into this trend, we study over 1500 quantized LLM checkpoints of various sizes and at different training levels (undertrained or fully trained) in a controlled setting, deriving scaling laws for understanding the relationship between QiD and factors such as the number of training tokens, model size and bit width. With the derived scaling laws, we propose a novel perspective that we can use QiD to measure an LLM's training levels and determine the number of training tokens required for fully training LLMs of various sizes. Moreover, we use the scaling laws to predict the quantization performance of different-sized LLMs trained with 100 trillion tokens. Our projection shows that the low-bit quantization performance of future models, which are expected to be trained with over 100 trillion tokens, may NOT be desirable. This poses a potential challenge for low-bit quantization in the future and highlights the need for awareness of a model's training level when evaluating low-bit quantization research. To facilitate future research on this problem, we release all the 1500+ quantized checkpoints used in this work at https://huggingface.co/Xu-Ouyang.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Ouyang","given":"Xu"},{"family":"Ge","given":"Tao"},{"family":"Hartvigsen","given":"Thomas"},{"family":"Zhang","given":"Zhisong"},{"family":"Mi","given":"Haitao"},{"family":"Yu","given":"Dong"}],"citation-key":"ouyangLowBitQuantizationFavors2024","DOI":"10.48550/arXiv.2411.17691","issued":{"date-parts":[["2024",11,27]]},"number":"arXiv:2411.17691","publisher":"arXiv","source":"arXiv.org","title":"Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens","title-short":"Low-Bit Quantization Favors Undertrained LLMs","type":"article","URL":"http://arxiv.org/abs/2411.17691"},
  {"id":"pagnoniByteLatentTransformer2024","abstract":"We introduce the Byte Latent Transformer (BLT), a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness. BLT encodes bytes into dynamically sized patches, which serve as the primary units of computation. Patches are segmented based on the entropy of the next byte, allocating more compute and model capacity where increased data complexity demands it. We present the first FLOP controlled scaling study of byte-level models up to 8B parameters and 4T training bytes. Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Pagnoni","given":"Artidoro"},{"family":"Pasunuru","given":"Ram"},{"family":"Rodriguez","given":"Pedro"},{"family":"Nguyen","given":"John"},{"family":"Muller","given":"Benjamin"},{"family":"Li","given":"Margaret"},{"family":"Zhou","given":"Chunting"},{"family":"Yu","given":"Lili"},{"family":"Weston","given":"Jason"},{"family":"Zettlemoyer","given":"Luke"},{"family":"Ghosh","given":"Gargi"},{"family":"Lewis","given":"Mike"},{"family":"Holtzman","given":"Ari"},{"family":"Iyer","given":"Srinivasan"}],"citation-key":"pagnoniByteLatentTransformer2024","DOI":"10.48550/arXiv.2412.09871","issued":{"date-parts":[["2024",12,13]]},"number":"arXiv:2412.09871","publisher":"arXiv","source":"arXiv.org","title":"Byte Latent Transformer: Patches Scale Better Than Tokens","title-short":"Byte Latent Transformer","type":"article","URL":"http://arxiv.org/abs/2412.09871"},
  {"id":"penedoFineWebDatasetsDecanting2024","abstract":"The performance of a large language model (LLM) depends heavily on the quality and size of its pretraining dataset. However, the pretraining datasets for state-of-the-art open LLMs like Llama 3 and Mixtral are not publicly available and very little is known about how they were created. In this work, we introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl snapshots that produces better-performing LLMs than other open pretraining datasets. To advance the understanding of how best to curate high-quality pretraining datasets, we carefully document and ablate all of the design choices used in FineWeb, including in-depth investigations of deduplication and filtering strategies. In addition, we introduce FineWeb-Edu, a 1.3-trillion token collection of educational text filtered from FineWeb. LLMs pretrained on FineWeb-Edu exhibit dramatically better performance on knowledge- and reasoning-intensive benchmarks like MMLU and ARC. Along with our datasets, we publicly release our data curation codebase and all of the models trained during our ablation experiments.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Penedo","given":"Guilherme"},{"family":"Kydlíček","given":"Hynek"},{"family":"allal","given":"Loubna Ben"},{"family":"Lozhkov","given":"Anton"},{"family":"Mitchell","given":"Margaret"},{"family":"Raffel","given":"Colin"},{"family":"Werra","given":"Leandro Von"},{"family":"Wolf","given":"Thomas"}],"citation-key":"penedoFineWebDatasetsDecanting2024","DOI":"10.48550/arXiv.2406.17557","issued":{"date-parts":[["2024",10,31]]},"number":"arXiv:2406.17557","publisher":"arXiv","source":"arXiv.org","title":"The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale","title-short":"The FineWeb Datasets","type":"article","URL":"http://arxiv.org/abs/2406.17557"},
  {"id":"pengRWKVReinventingRNNs2023","abstract":"Transformers have revolutionized almost all natural language processing (NLP) tasks but suffer from memory and computational complexity that scales quadratically with sequence length. In contrast, recurrent neural networks (RNNs) exhibit linear scaling in memory and computational requirements but struggle to match the same performance as Transformers due to limitations in parallelization and scalability. We propose a novel model architecture, Receptance Weighted Key Value (RWKV), that combines the efficient parallelizable training of transformers with the efficient inference of RNNs. Our approach leverages a linear attention mechanism and allows us to formulate the model as either a Transformer or an RNN, thus parallelizing computations during training and maintains constant computational and memory complexity during inference. We scale our models as large as 14 billion parameters, by far the largest dense RNN ever trained, and find RWKV performs on par with similarly sized Transformers, suggesting future work can leverage this architecture to create more efficient models. This work presents a significant step towards reconciling trade-offs between computational efficiency and model performance in sequence processing tasks.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Peng","given":"Bo"},{"family":"Alcaide","given":"Eric"},{"family":"Anthony","given":"Quentin"},{"family":"Albalak","given":"Alon"},{"family":"Arcadinho","given":"Samuel"},{"family":"Biderman","given":"Stella"},{"family":"Cao","given":"Huanqi"},{"family":"Cheng","given":"Xin"},{"family":"Chung","given":"Michael"},{"family":"Grella","given":"Matteo"},{"family":"GV","given":"Kranthi Kiran"},{"family":"He","given":"Xuzheng"},{"family":"Hou","given":"Haowen"},{"family":"Lin","given":"Jiaju"},{"family":"Kazienko","given":"Przemyslaw"},{"family":"Kocon","given":"Jan"},{"family":"Kong","given":"Jiaming"},{"family":"Koptyra","given":"Bartlomiej"},{"family":"Lau","given":"Hayden"},{"family":"Mantri","given":"Krishna Sri Ipsit"},{"family":"Mom","given":"Ferdinand"},{"family":"Saito","given":"Atsushi"},{"family":"Song","given":"Guangyu"},{"family":"Tang","given":"Xiangru"},{"family":"Wang","given":"Bolun"},{"family":"Wind","given":"Johan S."},{"family":"Wozniak","given":"Stanislaw"},{"family":"Zhang","given":"Ruichong"},{"family":"Zhang","given":"Zhenyuan"},{"family":"Zhao","given":"Qihang"},{"family":"Zhou","given":"Peng"},{"family":"Zhou","given":"Qinghua"},{"family":"Zhu","given":"Jian"},{"family":"Zhu","given":"Rui-Jie"}],"citation-key":"pengRWKVReinventingRNNs2023","DOI":"10.48550/arXiv.2305.13048","issued":{"date-parts":[["2023",12,11]]},"number":"arXiv:2305.13048","publisher":"arXiv","source":"arXiv.org","title":"RWKV: Reinventing RNNs for the Transformer Era","title-short":"RWKV","type":"article","URL":"http://arxiv.org/abs/2305.13048"},
  {"id":"qwenQwen25TechnicalReport2024","abstract":"In this report, we introduce Qwen2.5, a comprehensive series of large language models (LLMs) designed to meet diverse needs. Compared to previous iterations, Qwen 2.5 has been significantly improved during both the pre-training and post-training stages. In terms of pre-training, we have scaled the high-quality pre-training datasets from the previous 7 trillion tokens to 18 trillion tokens. This provides a strong foundation for common sense, expert knowledge, and reasoning capabilities. In terms of post-training, we implement intricate supervised finetuning with over 1 million samples, as well as multistage reinforcement learning. Post-training techniques enhance human preference, and notably improve long text generation, structural data analysis, and instruction following. To handle diverse and varied use cases effectively, we present Qwen2.5 LLM series in rich sizes. Open-weight offerings include base and instruction-tuned models, with quantized versions available. In addition, for hosted solutions, the proprietary models currently include two mixture-of-experts (MoE) variants: Qwen2.5-Turbo and Qwen2.5-Plus, both available from Alibaba Cloud Model Studio. Qwen2.5 has demonstrated top-tier performance on a wide range of benchmarks evaluating language understanding, reasoning, mathematics, coding, human preference alignment, etc. Specifically, the open-weight flagship Qwen2.5-72B-Instruct outperforms a number of open and proprietary models and demonstrates competitive performance to the state-of-the-art open-weight model, Llama-3-405B-Instruct, which is around 5 times larger. Qwen2.5-Turbo and Qwen2.5-Plus offer superior cost-effectiveness while performing competitively against GPT-4o-mini and GPT-4o respectively. Additionally, as the foundation, Qwen2.5 models have been instrumental in training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and multimodal models.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Qwen","given":""},{"family":"Yang","given":"An"},{"family":"Yang","given":"Baosong"},{"family":"Zhang","given":"Beichen"},{"family":"Hui","given":"Binyuan"},{"family":"Zheng","given":"Bo"},{"family":"Yu","given":"Bowen"},{"family":"Li","given":"Chengyuan"},{"family":"Liu","given":"Dayiheng"},{"family":"Huang","given":"Fei"},{"family":"Wei","given":"Haoran"},{"family":"Lin","given":"Huan"},{"family":"Yang","given":"Jian"},{"family":"Tu","given":"Jianhong"},{"family":"Zhang","given":"Jianwei"},{"family":"Yang","given":"Jianxin"},{"family":"Yang","given":"Jiaxi"},{"family":"Zhou","given":"Jingren"},{"family":"Lin","given":"Junyang"},{"family":"Dang","given":"Kai"},{"family":"Lu","given":"Keming"},{"family":"Bao","given":"Keqin"},{"family":"Yang","given":"Kexin"},{"family":"Yu","given":"Le"},{"family":"Li","given":"Mei"},{"family":"Xue","given":"Mingfeng"},{"family":"Zhang","given":"Pei"},{"family":"Zhu","given":"Qin"},{"family":"Men","given":"Rui"},{"family":"Lin","given":"Runji"},{"family":"Li","given":"Tianhao"},{"family":"Xia","given":"Tingyu"},{"family":"Ren","given":"Xingzhang"},{"family":"Ren","given":"Xuancheng"},{"family":"Fan","given":"Yang"},{"family":"Su","given":"Yang"},{"family":"Zhang","given":"Yichang"},{"family":"Wan","given":"Yu"},{"family":"Liu","given":"Yuqiong"},{"family":"Cui","given":"Zeyu"},{"family":"Zhang","given":"Zhenru"},{"family":"Qiu","given":"Zihan"}],"citation-key":"qwenQwen25TechnicalReport2024","DOI":"10.48550/arXiv.2412.15115","issued":{"date-parts":[["2024",12,19]]},"number":"arXiv:2412.15115","publisher":"arXiv","source":"arXiv.org","title":"Qwen2.5 Technical Report","type":"article","URL":"http://arxiv.org/abs/2412.15115"},
  {"id":"riedlerTextOptimizingRAG2024","abstract":"Large Language Models (LLMs) have demonstrated impressive capabilities in answering questions, but they lack domain-specific knowledge and are prone to hallucinations. Retrieval Augmented Generation (RAG) is one approach to address these challenges, while multimodal models are emerging as promising AI assistants for processing both text and images. In this paper we describe a series of experiments aimed at determining how to best integrate multimodal models into RAG systems for the industrial domain. The purpose of the experiments is to determine whether including images alongside text from documents within the industrial domain increases RAG performance and to find the optimal configuration for such a multimodal RAG system. Our experiments include two approaches for image processing and retrieval, as well as two LLMs (GPT4-Vision and LLaVA) for answer synthesis. These image processing strategies involve the use of multimodal embeddings and the generation of textual summaries from images. We evaluate our experiments with an LLM-as-a-Judge approach. Our results reveal that multimodal RAG can outperform single-modality RAG settings, although image retrieval poses a greater challenge than text retrieval. Additionally, leveraging textual summaries from images presents a more promising approach compared to the use of multimodal embeddings, providing more opportunities for future advancements.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Riedler","given":"Monica"},{"family":"Langer","given":"Stefan"}],"citation-key":"riedlerTextOptimizingRAG2024","DOI":"10.48550/arXiv.2410.21943","issued":{"date-parts":[["2024",10,29]]},"number":"arXiv:2410.21943","publisher":"arXiv","source":"arXiv.org","title":"Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications","title-short":"Beyond Text","type":"article","URL":"http://arxiv.org/abs/2410.21943"},
  {"id":"spragueCoTNotCoT2024","abstract":"Chain-of-thought (CoT) via prompting is the de facto method for eliciting reasoning capabilities from large language models (LLMs). But for what kinds of tasks is this extra ``thinking'' really helpful? To analyze this, we conducted a quantitative meta-analysis covering over 100 papers using CoT and ran our own evaluations of 20 datasets across 14 models. Our results show that CoT gives strong performance benefits primarily on tasks involving math or logic, with much smaller gains on other types of tasks. On MMLU, directly generating the answer without CoT leads to almost identical accuracy as CoT unless the question or model's response contains an equals sign, indicating symbolic operations and reasoning. Following this finding, we analyze the behavior of CoT on these problems by separating planning and execution and comparing against tool-augmented LLMs. Much of CoT's gain comes from improving symbolic execution, but it underperforms relative to using a symbolic solver. Our results indicate that CoT can be applied selectively, maintaining performance while saving inference costs. Furthermore, they suggest a need to move beyond prompt-based CoT to new paradigms that better leverage intermediate computation across the whole range of LLM applications.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Sprague","given":"Zayne"},{"family":"Yin","given":"Fangcong"},{"family":"Rodriguez","given":"Juan Diego"},{"family":"Jiang","given":"Dongwei"},{"family":"Wadhwa","given":"Manya"},{"family":"Singhal","given":"Prasann"},{"family":"Zhao","given":"Xinyu"},{"family":"Ye","given":"Xi"},{"family":"Mahowald","given":"Kyle"},{"family":"Durrett","given":"Greg"}],"citation-key":"spragueCoTNotCoT2024","DOI":"10.48550/arXiv.2409.12183","issued":{"date-parts":[["2024",10,29]]},"number":"arXiv:2409.12183","publisher":"arXiv","source":"arXiv.org","title":"To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning","title-short":"To CoT or not to CoT?","type":"article","URL":"http://arxiv.org/abs/2409.12183"},
  {"id":"sunShadowKVKVCache2024","abstract":"With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for each token generation both result in low throughput when serving long-context LLMs. While various dynamic sparse attention methods have been proposed to speed up inference while maintaining generation quality, they either fail to sufficiently reduce GPU memory consumption or introduce significant decoding latency by offloading the KV cache to the CPU. We present ShadowKV, a high-throughput long-context LLM inference system that stores the low-rank key cache and offloads the value cache to reduce the memory footprint for larger batch sizes and longer sequences. To minimize decoding latency, ShadowKV employs an accurate KV selection strategy that reconstructs minimal sparse KV pairs on-the-fly. By evaluating ShadowKV on a broad range of benchmarks, including RULER, LongBench, and Needle In A Haystack, and models like Llama-3.1-8B, Llama-3-8B-1M, GLM-4-9B-1M, Yi-9B-200K, Phi-3-Mini-128K, and Qwen2-7B-128K, we demonstrate that it can support up to 6$\\times$ larger batch sizes and boost throughput by up to 3.04$\\times$ on an A100 GPU without sacrificing accuracy, even surpassing the performance achievable with infinite batch size under the assumption of infinite GPU memory. The code is available at https://github.com/bytedance/ShadowKV.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Sun","given":"Hanshi"},{"family":"Chang","given":"Li-Wen"},{"family":"Bao","given":"Wenlei"},{"family":"Zheng","given":"Size"},{"family":"Zheng","given":"Ningxin"},{"family":"Liu","given":"Xin"},{"family":"Dong","given":"Harry"},{"family":"Chi","given":"Yuejie"},{"family":"Chen","given":"Beidi"}],"citation-key":"sunShadowKVKVCache2024","DOI":"10.48550/arXiv.2410.21465","issued":{"date-parts":[["2024",10,28]]},"number":"arXiv:2410.21465","publisher":"arXiv","source":"arXiv.org","title":"ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference","title-short":"ShadowKV","type":"article","URL":"http://arxiv.org/abs/2410.21465"},
  {"id":"teamGeminiFamilyHighly2024","abstract":"This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Team","given":"Gemini"},{"family":"Anil","given":"Rohan"},{"family":"Borgeaud","given":"Sebastian"},{"family":"Alayrac","given":"Jean-Baptiste"},{"family":"Yu","given":"Jiahui"},{"family":"Soricut","given":"Radu"},{"family":"Schalkwyk","given":"Johan"},{"family":"Dai","given":"Andrew M."},{"family":"Hauth","given":"Anja"},{"family":"Millican","given":"Katie"},{"family":"Silver","given":"David"},{"family":"Johnson","given":"Melvin"},{"family":"Antonoglou","given":"Ioannis"},{"family":"Schrittwieser","given":"Julian"},{"family":"Glaese","given":"Amelia"},{"family":"Chen","given":"Jilin"},{"family":"Pitler","given":"Emily"},{"family":"Lillicrap","given":"Timothy"},{"family":"Lazaridou","given":"Angeliki"},{"family":"Firat","given":"Orhan"},{"family":"Molloy","given":"James"},{"family":"Isard","given":"Michael"},{"family":"Barham","given":"Paul R."},{"family":"Hennigan","given":"Tom"},{"family":"Lee","given":"Benjamin"},{"family":"Viola","given":"Fabio"},{"family":"Reynolds","given":"Malcolm"},{"family":"Xu","given":"Yuanzhong"},{"family":"Doherty","given":"Ryan"},{"family":"Collins","given":"Eli"},{"family":"Meyer","given":"Clemens"},{"family":"Rutherford","given":"Eliza"},{"family":"Moreira","given":"Erica"},{"family":"Ayoub","given":"Kareem"},{"family":"Goel","given":"Megha"},{"family":"Krawczyk","given":"Jack"},{"family":"Du","given":"Cosmo"},{"family":"Chi","given":"Ed"},{"family":"Cheng","given":"Heng-Tze"},{"family":"Ni","given":"Eric"},{"family":"Shah","given":"Purvi"},{"family":"Kane","given":"Patrick"},{"family":"Chan","given":"Betty"},{"family":"Faruqui","given":"Manaal"},{"family":"Severyn","given":"Aliaksei"},{"family":"Lin","given":"Hanzhao"},{"family":"Li","given":"YaGuang"},{"family":"Cheng","given":"Yong"},{"family":"Ittycheriah","given":"Abe"},{"family":"Mahdieh","given":"Mahdis"},{"family":"Chen","given":"Mia"},{"family":"Sun","given":"Pei"},{"family":"Tran","given":"Dustin"},{"family":"Bagri","given":"Sumit"},{"family":"Lakshminarayanan","given":"Balaji"},{"family":"Liu","given":"Jeremiah"},{"family":"Orban","given":"Andras"},{"family":"Güra","given":"Fabian"},{"family":"Zhou","given":"Hao"},{"family":"Song","given":"Xinying"},{"family":"Boffy","given":"Aurelien"},{"family":"Ganapathy","given":"Harish"},{"family":"Zheng","given":"Steven"},{"family":"Choe","given":"HyunJeong"},{"family":"Weisz","given":"Ágoston"},{"family":"Zhu","given":"Tao"},{"family":"Lu","given":"Yifeng"},{"family":"Gopal","given":"Siddharth"},{"family":"Kahn","given":"Jarrod"},{"family":"Kula","given":"Maciej"},{"family":"Pitman","given":"Jeff"},{"family":"Shah","given":"Rushin"},{"family":"Taropa","given":"Emanuel"},{"family":"Merey","given":"Majd Al"},{"family":"Baeuml","given":"Martin"},{"family":"Chen","given":"Zhifeng"},{"family":"Shafey","given":"Laurent El"},{"family":"Zhang","given":"Yujing"},{"family":"Sercinoglu","given":"Olcan"},{"family":"Tucker","given":"George"},{"family":"Piqueras","given":"Enrique"},{"family":"Krikun","given":"Maxim"},{"family":"Barr","given":"Iain"},{"family":"Savinov","given":"Nikolay"},{"family":"Danihelka","given":"Ivo"},{"family":"Roelofs","given":"Becca"},{"family":"White","given":"Anaïs"},{"family":"Andreassen","given":"Anders"},{"family":"Glehn","given":"Tamara","dropping-particle":"von"},{"family":"Yagati","given":"Lakshman"},{"family":"Kazemi","given":"Mehran"},{"family":"Gonzalez","given":"Lucas"},{"family":"Khalman","given":"Misha"},{"family":"Sygnowski","given":"Jakub"},{"family":"Frechette","given":"Alexandre"},{"family":"Smith","given":"Charlotte"},{"family":"Culp","given":"Laura"},{"family":"Proleev","given":"Lev"},{"family":"Luan","given":"Yi"},{"family":"Chen","given":"Xi"},{"family":"Lottes","given":"James"},{"family":"Schucher","given":"Nathan"},{"family":"Lebron","given":"Federico"},{"family":"Rrustemi","given":"Alban"},{"family":"Clay","given":"Natalie"},{"family":"Crone","given":"Phil"},{"family":"Kocisky","given":"Tomas"},{"family":"Zhao","given":"Jeffrey"},{"family":"Perz","given":"Bartek"},{"family":"Yu","given":"Dian"},{"family":"Howard","given":"Heidi"},{"family":"Bloniarz","given":"Adam"},{"family":"Rae","given":"Jack W."},{"family":"Lu","given":"Han"},{"family":"Sifre","given":"Laurent"},{"family":"Maggioni","given":"Marcello"},{"family":"Alcober","given":"Fred"},{"family":"Garrette","given":"Dan"},{"family":"Barnes","given":"Megan"},{"family":"Thakoor","given":"Shantanu"},{"family":"Austin","given":"Jacob"},{"family":"Barth-Maron","given":"Gabriel"},{"family":"Wong","given":"William"},{"family":"Joshi","given":"Rishabh"},{"family":"Chaabouni","given":"Rahma"},{"family":"Fatiha","given":"Deeni"},{"family":"Ahuja","given":"Arun"},{"family":"Tomar","given":"Gaurav Singh"},{"family":"Senter","given":"Evan"},{"family":"Chadwick","given":"Martin"},{"family":"Kornakov","given":"Ilya"},{"family":"Attaluri","given":"Nithya"},{"family":"Iturrate","given":"Iñaki"},{"family":"Liu","given":"Ruibo"},{"family":"Li","given":"Yunxuan"},{"family":"Cogan","given":"Sarah"},{"family":"Chen","given":"Jeremy"},{"family":"Jia","given":"Chao"},{"family":"Gu","given":"Chenjie"},{"family":"Zhang","given":"Qiao"},{"family":"Grimstad","given":"Jordan"},{"family":"Hartman","given":"Ale Jakse"},{"family":"Garcia","given":"Xavier"},{"family":"Pillai","given":"Thanumalayan Sankaranarayana"},{"family":"Devlin","given":"Jacob"},{"family":"Laskin","given":"Michael"},{"family":"Casas","given":"Diego de Las"},{"family":"Valter","given":"Dasha"},{"family":"Tao","given":"Connie"},{"family":"Blanco","given":"Lorenzo"},{"family":"Badia","given":"Adrià Puigdomènech"},{"family":"Reitter","given":"David"},{"family":"Chen","given":"Mianna"},{"family":"Brennan","given":"Jenny"},{"family":"Rivera","given":"Clara"},{"family":"Brin","given":"Sergey"},{"family":"Iqbal","given":"Shariq"},{"family":"Surita","given":"Gabriela"},{"family":"Labanowski","given":"Jane"},{"family":"Rao","given":"Abhi"},{"family":"Winkler","given":"Stephanie"},{"family":"Parisotto","given":"Emilio"},{"family":"Gu","given":"Yiming"},{"family":"Olszewska","given":"Kate"},{"family":"Addanki","given":"Ravi"},{"family":"Miech","given":"Antoine"},{"family":"Louis","given":"Annie"},{"family":"Teplyashin","given":"Denis"},{"family":"Brown","given":"Geoff"},{"family":"Catt","given":"Elliot"},{"family":"Balaguer","given":"Jan"},{"family":"Xiang","given":"Jackie"},{"family":"Wang","given":"Pidong"},{"family":"Ashwood","given":"Zoe"},{"family":"Briukhov","given":"Anton"},{"family":"Webson","given":"Albert"},{"family":"Ganapathy","given":"Sanjay"},{"family":"Sanghavi","given":"Smit"},{"family":"Kannan","given":"Ajay"},{"family":"Chang","given":"Ming-Wei"},{"family":"Stjerngren","given":"Axel"},{"family":"Djolonga","given":"Josip"},{"family":"Sun","given":"Yuting"},{"family":"Bapna","given":"Ankur"},{"family":"Aitchison","given":"Matthew"},{"family":"Pejman","given":"Pedram"},{"family":"Michalewski","given":"Henryk"},{"family":"Yu","given":"Tianhe"},{"family":"Wang","given":"Cindy"},{"family":"Love","given":"Juliette"},{"family":"Ahn","given":"Junwhan"},{"family":"Bloxwich","given":"Dawn"},{"family":"Han","given":"Kehang"},{"family":"Humphreys","given":"Peter"},{"family":"Sellam","given":"Thibault"},{"family":"Bradbury","given":"James"},{"family":"Godbole","given":"Varun"},{"family":"Samangooei","given":"Sina"},{"family":"Damoc","given":"Bogdan"},{"family":"Kaskasoli","given":"Alex"},{"family":"Arnold","given":"Sébastien M. R."},{"family":"Vasudevan","given":"Vijay"},{"family":"Agrawal","given":"Shubham"},{"family":"Riesa","given":"Jason"},{"family":"Lepikhin","given":"Dmitry"},{"family":"Tanburn","given":"Richard"},{"family":"Srinivasan","given":"Srivatsan"},{"family":"Lim","given":"Hyeontaek"},{"family":"Hodkinson","given":"Sarah"},{"family":"Shyam","given":"Pranav"},{"family":"Ferret","given":"Johan"},{"family":"Hand","given":"Steven"},{"family":"Garg","given":"Ankush"},{"family":"Paine","given":"Tom Le"},{"family":"Li","given":"Jian"},{"family":"Li","given":"Yujia"},{"family":"Giang","given":"Minh"},{"family":"Neitz","given":"Alexander"},{"family":"Abbas","given":"Zaheer"},{"family":"York","given":"Sarah"},{"family":"Reid","given":"Machel"},{"family":"Cole","given":"Elizabeth"},{"family":"Chowdhery","given":"Aakanksha"},{"family":"Das","given":"Dipanjan"},{"family":"Rogozińska","given":"Dominika"},{"family":"Nikolaev","given":"Vitaliy"},{"family":"Sprechmann","given":"Pablo"},{"family":"Nado","given":"Zachary"},{"family":"Zilka","given":"Lukas"},{"family":"Prost","given":"Flavien"},{"family":"He","given":"Luheng"},{"family":"Monteiro","given":"Marianne"},{"family":"Mishra","given":"Gaurav"},{"family":"Welty","given":"Chris"},{"family":"Newlan","given":"Josh"},{"family":"Jia","given":"Dawei"},{"family":"Allamanis","given":"Miltiadis"},{"family":"Hu","given":"Clara Huiyi"},{"family":"Liedekerke","given":"Raoul","dropping-particle":"de"},{"family":"Gilmer","given":"Justin"},{"family":"Saroufim","given":"Carl"},{"family":"Rijhwani","given":"Shruti"},{"family":"Hou","given":"Shaobo"},{"family":"Shrivastava","given":"Disha"},{"family":"Baddepudi","given":"Anirudh"},{"family":"Goldin","given":"Alex"},{"family":"Ozturel","given":"Adnan"},{"family":"Cassirer","given":"Albin"},{"family":"Xu","given":"Yunhan"},{"family":"Sohn","given":"Daniel"},{"family":"Sachan","given":"Devendra"},{"family":"Amplayo","given":"Reinald Kim"},{"family":"Swanson","given":"Craig"},{"family":"Petrova","given":"Dessie"},{"family":"Narayan","given":"Shashi"},{"family":"Guez","given":"Arthur"},{"family":"Brahma","given":"Siddhartha"},{"family":"Landon","given":"Jessica"},{"family":"Patel","given":"Miteyan"},{"family":"Zhao","given":"Ruizhe"},{"family":"Villela","given":"Kevin"},{"family":"Wang","given":"Luyu"},{"family":"Jia","given":"Wenhao"},{"family":"Rahtz","given":"Matthew"},{"family":"Giménez","given":"Mai"},{"family":"Yeung","given":"Legg"},{"family":"Keeling","given":"James"},{"family":"Georgiev","given":"Petko"},{"family":"Mincu","given":"Diana"},{"family":"Wu","given":"Boxi"},{"family":"Haykal","given":"Salem"},{"family":"Saputro","given":"Rachel"},{"family":"Vodrahalli","given":"Kiran"},{"family":"Qin","given":"James"},{"family":"Cankara","given":"Zeynep"},{"family":"Sharma","given":"Abhanshu"},{"family":"Fernando","given":"Nick"},{"family":"Hawkins","given":"Will"},{"family":"Neyshabur","given":"Behnam"},{"family":"Kim","given":"Solomon"},{"family":"Hutter","given":"Adrian"},{"family":"Agrawal","given":"Priyanka"},{"family":"Castro-Ros","given":"Alex"},{"family":"Driessche","given":"George","dropping-particle":"van den"},{"family":"Wang","given":"Tao"},{"family":"Yang","given":"Fan"},{"family":"Chang","given":"Shuo-yiin"},{"family":"Komarek","given":"Paul"},{"family":"McIlroy","given":"Ross"},{"family":"Lučić","given":"Mario"},{"family":"Zhang","given":"Guodong"},{"family":"Farhan","given":"Wael"},{"family":"Sharman","given":"Michael"},{"family":"Natsev","given":"Paul"},{"family":"Michel","given":"Paul"},{"family":"Bansal","given":"Yamini"},{"family":"Qiao","given":"Siyuan"},{"family":"Cao","given":"Kris"},{"family":"Shakeri","given":"Siamak"},{"family":"Butterfield","given":"Christina"},{"family":"Chung","given":"Justin"},{"family":"Rubenstein","given":"Paul Kishan"},{"family":"Agrawal","given":"Shivani"},{"family":"Mensch","given":"Arthur"},{"family":"Soparkar","given":"Kedar"},{"family":"Lenc","given":"Karel"},{"family":"Chung","given":"Timothy"},{"family":"Pope","given":"Aedan"},{"family":"Maggiore","given":"Loren"},{"family":"Kay","given":"Jackie"},{"family":"Jhakra","given":"Priya"},{"family":"Wang","given":"Shibo"},{"family":"Maynez","given":"Joshua"},{"family":"Phuong","given":"Mary"},{"family":"Tobin","given":"Taylor"},{"family":"Tacchetti","given":"Andrea"},{"family":"Trebacz","given":"Maja"},{"family":"Robinson","given":"Kevin"},{"family":"Katariya","given":"Yash"},{"family":"Riedel","given":"Sebastian"},{"family":"Bailey","given":"Paige"},{"family":"Xiao","given":"Kefan"},{"family":"Ghelani","given":"Nimesh"},{"family":"Aroyo","given":"Lora"},{"family":"Slone","given":"Ambrose"},{"family":"Houlsby","given":"Neil"},{"family":"Xiong","given":"Xuehan"},{"family":"Yang","given":"Zhen"},{"family":"Gribovskaya","given":"Elena"},{"family":"Adler","given":"Jonas"},{"family":"Wirth","given":"Mateo"},{"family":"Lee","given":"Lisa"},{"family":"Li","given":"Music"},{"family":"Kagohara","given":"Thais"},{"family":"Pavagadhi","given":"Jay"},{"family":"Bridgers","given":"Sophie"},{"family":"Bortsova","given":"Anna"},{"family":"Ghemawat","given":"Sanjay"},{"family":"Ahmed","given":"Zafarali"},{"family":"Liu","given":"Tianqi"},{"family":"Powell","given":"Richard"},{"family":"Bolina","given":"Vijay"},{"family":"Iinuma","given":"Mariko"},{"family":"Zablotskaia","given":"Polina"},{"family":"Besley","given":"James"},{"family":"Chung","given":"Da-Woon"},{"family":"Dozat","given":"Timothy"},{"family":"Comanescu","given":"Ramona"},{"family":"Si","given":"Xiance"},{"family":"Greer","given":"Jeremy"},{"family":"Su","given":"Guolong"},{"family":"Polacek","given":"Martin"},{"family":"Kaufman","given":"Raphaël Lopez"},{"family":"Tokumine","given":"Simon"},{"family":"Hu","given":"Hexiang"},{"family":"Buchatskaya","given":"Elena"},{"family":"Miao","given":"Yingjie"},{"family":"Elhawaty","given":"Mohamed"},{"family":"Siddhant","given":"Aditya"},{"family":"Tomasev","given":"Nenad"},{"family":"Xing","given":"Jinwei"},{"family":"Greer","given":"Christina"},{"family":"Miller","given":"Helen"},{"family":"Ashraf","given":"Shereen"},{"family":"Roy","given":"Aurko"},{"family":"Zhang","given":"Zizhao"},{"family":"Ma","given":"Ada"},{"family":"Filos","given":"Angelos"},{"family":"Besta","given":"Milos"},{"family":"Blevins","given":"Rory"},{"family":"Klimenko","given":"Ted"},{"family":"Yeh","given":"Chih-Kuan"},{"family":"Changpinyo","given":"Soravit"},{"family":"Mu","given":"Jiaqi"},{"family":"Chang","given":"Oscar"},{"family":"Pajarskas","given":"Mantas"},{"family":"Muir","given":"Carrie"},{"family":"Cohen","given":"Vered"},{"family":"Lan","given":"Charline Le"},{"family":"Haridasan","given":"Krishna"},{"family":"Marathe","given":"Amit"},{"family":"Hansen","given":"Steven"},{"family":"Douglas","given":"Sholto"},{"family":"Samuel","given":"Rajkumar"},{"family":"Wang","given":"Mingqiu"},{"family":"Austin","given":"Sophia"},{"family":"Lan","given":"Chang"},{"family":"Jiang","given":"Jiepu"},{"family":"Chiu","given":"Justin"},{"family":"Lorenzo","given":"Jaime Alonso"},{"family":"Sjösund","given":"Lars Lowe"},{"family":"Cevey","given":"Sébastien"},{"family":"Gleicher","given":"Zach"},{"family":"Avrahami","given":"Thi"},{"family":"Boral","given":"Anudhyan"},{"family":"Srinivasan","given":"Hansa"},{"family":"Selo","given":"Vittorio"},{"family":"May","given":"Rhys"},{"family":"Aisopos","given":"Konstantinos"},{"family":"Hussenot","given":"Léonard"},{"family":"Soares","given":"Livio Baldini"},{"family":"Baumli","given":"Kate"},{"family":"Chang","given":"Michael B."},{"family":"Recasens","given":"Adrià"},{"family":"Caine","given":"Ben"},{"family":"Pritzel","given":"Alexander"},{"family":"Pavetic","given":"Filip"},{"family":"Pardo","given":"Fabio"},{"family":"Gergely","given":"Anita"},{"family":"Frye","given":"Justin"},{"family":"Ramasesh","given":"Vinay"},{"family":"Horgan","given":"Dan"},{"family":"Badola","given":"Kartikeya"},{"family":"Kassner","given":"Nora"},{"family":"Roy","given":"Subhrajit"},{"family":"Dyer","given":"Ethan"},{"family":"Campos","given":"Víctor Campos"},{"family":"Tomala","given":"Alex"},{"family":"Tang","given":"Yunhao"},{"family":"Badawy","given":"Dalia El"},{"family":"White","given":"Elspeth"},{"family":"Mustafa","given":"Basil"},{"family":"Lang","given":"Oran"},{"family":"Jindal","given":"Abhishek"},{"family":"Vikram","given":"Sharad"},{"family":"Gong","given":"Zhitao"},{"family":"Caelles","given":"Sergi"},{"family":"Hemsley","given":"Ross"},{"family":"Thornton","given":"Gregory"},{"family":"Feng","given":"Fangxiaoyu"},{"family":"Stokowiec","given":"Wojciech"},{"family":"Zheng","given":"Ce"},{"family":"Thacker","given":"Phoebe"},{"family":"Ünlü","given":"Çağlar"},{"family":"Zhang","given":"Zhishuai"},{"family":"Saleh","given":"Mohammad"},{"family":"Svensson","given":"James"},{"family":"Bileschi","given":"Max"},{"family":"Patil","given":"Piyush"},{"family":"Anand","given":"Ankesh"},{"family":"Ring","given":"Roman"},{"family":"Tsihlas","given":"Katerina"},{"family":"Vezer","given":"Arpi"},{"family":"Selvi","given":"Marco"},{"family":"Shevlane","given":"Toby"},{"family":"Rodriguez","given":"Mikel"},{"family":"Kwiatkowski","given":"Tom"},{"family":"Daruki","given":"Samira"},{"family":"Rong","given":"Keran"},{"family":"Dafoe","given":"Allan"},{"family":"FitzGerald","given":"Nicholas"},{"family":"Gu-Lemberg","given":"Keren"},{"family":"Khan","given":"Mina"},{"family":"Hendricks","given":"Lisa Anne"},{"family":"Pellat","given":"Marie"},{"family":"Feinberg","given":"Vladimir"},{"family":"Cobon-Kerr","given":"James"},{"family":"Sainath","given":"Tara"},{"family":"Rauh","given":"Maribeth"},{"family":"Hashemi","given":"Sayed Hadi"},{"family":"Ives","given":"Richard"},{"family":"Hasson","given":"Yana"},{"family":"Noland","given":"Eric"},{"family":"Cao","given":"Yuan"},{"family":"Byrd","given":"Nathan"},{"family":"Hou","given":"Le"},{"family":"Wang","given":"Qingze"},{"family":"Sottiaux","given":"Thibault"},{"family":"Paganini","given":"Michela"},{"family":"Lespiau","given":"Jean-Baptiste"},{"family":"Moufarek","given":"Alexandre"},{"family":"Hassan","given":"Samer"},{"family":"Shivakumar","given":"Kaushik"},{"family":"Amersfoort","given":"Joost","dropping-particle":"van"},{"family":"Mandhane","given":"Amol"},{"family":"Joshi","given":"Pratik"},{"family":"Goyal","given":"Anirudh"},{"family":"Tung","given":"Matthew"},{"family":"Brock","given":"Andrew"},{"family":"Sheahan","given":"Hannah"},{"family":"Misra","given":"Vedant"},{"family":"Li","given":"Cheng"},{"family":"Rakićević","given":"Nemanja"},{"family":"Dehghani","given":"Mostafa"},{"family":"Liu","given":"Fangyu"},{"family":"Mittal","given":"Sid"},{"family":"Oh","given":"Junhyuk"},{"family":"Noury","given":"Seb"},{"family":"Sezener","given":"Eren"},{"family":"Huot","given":"Fantine"},{"family":"Lamm","given":"Matthew"},{"family":"Cao","given":"Nicola De"},{"family":"Chen","given":"Charlie"},{"family":"Mudgal","given":"Sidharth"},{"family":"Stella","given":"Romina"},{"family":"Brooks","given":"Kevin"},{"family":"Vasudevan","given":"Gautam"},{"family":"Liu","given":"Chenxi"},{"family":"Chain","given":"Mainak"},{"family":"Melinkeri","given":"Nivedita"},{"family":"Cohen","given":"Aaron"},{"family":"Wang","given":"Venus"},{"family":"Seymore","given":"Kristie"},{"family":"Zubkov","given":"Sergey"},{"family":"Goel","given":"Rahul"},{"family":"Yue","given":"Summer"},{"family":"Krishnakumaran","given":"Sai"},{"family":"Albert","given":"Brian"},{"family":"Hurley","given":"Nate"},{"family":"Sano","given":"Motoki"},{"family":"Mohananey","given":"Anhad"},{"family":"Joughin","given":"Jonah"},{"family":"Filonov","given":"Egor"},{"family":"Kępa","given":"Tomasz"},{"family":"Eldawy","given":"Yomna"},{"family":"Lim","given":"Jiawern"},{"family":"Rishi","given":"Rahul"},{"family":"Badiezadegan","given":"Shirin"},{"family":"Bos","given":"Taylor"},{"family":"Chang","given":"Jerry"},{"family":"Jain","given":"Sanil"},{"family":"Padmanabhan","given":"Sri Gayatri Sundara"},{"family":"Puttagunta","given":"Subha"},{"family":"Krishna","given":"Kalpesh"},{"family":"Baker","given":"Leslie"},{"family":"Kalb","given":"Norbert"},{"family":"Bedapudi","given":"Vamsi"},{"family":"Kurzrok","given":"Adam"},{"family":"Lei","given":"Shuntong"},{"family":"Yu","given":"Anthony"},{"family":"Litvin","given":"Oren"},{"family":"Zhou","given":"Xiang"},{"family":"Wu","given":"Zhichun"},{"family":"Sobell","given":"Sam"},{"family":"Siciliano","given":"Andrea"},{"family":"Papir","given":"Alan"},{"family":"Neale","given":"Robby"},{"family":"Bragagnolo","given":"Jonas"},{"family":"Toor","given":"Tej"},{"family":"Chen","given":"Tina"},{"family":"Anklin","given":"Valentin"},{"family":"Wang","given":"Feiran"},{"family":"Feng","given":"Richie"},{"family":"Gholami","given":"Milad"},{"family":"Ling","given":"Kevin"},{"family":"Liu","given":"Lijuan"},{"family":"Walter","given":"Jules"},{"family":"Moghaddam","given":"Hamid"},{"family":"Kishore","given":"Arun"},{"family":"Adamek","given":"Jakub"},{"family":"Mercado","given":"Tyler"},{"family":"Mallinson","given":"Jonathan"},{"family":"Wandekar","given":"Siddhinita"},{"family":"Cagle","given":"Stephen"},{"family":"Ofek","given":"Eran"},{"family":"Garrido","given":"Guillermo"},{"family":"Lombriser","given":"Clemens"},{"family":"Mukha","given":"Maksim"},{"family":"Sun","given":"Botu"},{"family":"Mohammad","given":"Hafeezul Rahman"},{"family":"Matak","given":"Josip"},{"family":"Qian","given":"Yadi"},{"family":"Peswani","given":"Vikas"},{"family":"Janus","given":"Pawel"},{"family":"Yuan","given":"Quan"},{"family":"Schelin","given":"Leif"},{"family":"David","given":"Oana"},{"family":"Garg","given":"Ankur"},{"family":"He","given":"Yifan"},{"family":"Duzhyi","given":"Oleksii"},{"family":"Älgmyr","given":"Anton"},{"family":"Lottaz","given":"Timothée"},{"family":"Li","given":"Qi"},{"family":"Yadav","given":"Vikas"},{"family":"Xu","given":"Luyao"},{"family":"Chinien","given":"Alex"},{"family":"Shivanna","given":"Rakesh"},{"family":"Chuklin","given":"Aleksandr"},{"family":"Li","given":"Josie"},{"family":"Spadine","given":"Carrie"},{"family":"Wolfe","given":"Travis"},{"family":"Mohamed","given":"Kareem"},{"family":"Das","given":"Subhabrata"},{"family":"Dai","given":"Zihang"},{"family":"He","given":"Kyle"},{"family":"Dincklage","given":"Daniel","dropping-particle":"von"},{"family":"Upadhyay","given":"Shyam"},{"family":"Maurya","given":"Akanksha"},{"family":"Chi","given":"Luyan"},{"family":"Krause","given":"Sebastian"},{"family":"Salama","given":"Khalid"},{"family":"Rabinovitch","given":"Pam G."},{"family":"M","given":"Pavan Kumar Reddy"},{"family":"Selvan","given":"Aarush"},{"family":"Dektiarev","given":"Mikhail"},{"family":"Ghiasi","given":"Golnaz"},{"family":"Guven","given":"Erdem"},{"family":"Gupta","given":"Himanshu"},{"family":"Liu","given":"Boyi"},{"family":"Sharma","given":"Deepak"},{"family":"Shtacher","given":"Idan Heimlich"},{"family":"Paul","given":"Shachi"},{"family":"Akerlund","given":"Oscar"},{"family":"Aubet","given":"François-Xavier"},{"family":"Huang","given":"Terry"},{"family":"Zhu","given":"Chen"},{"family":"Zhu","given":"Eric"},{"family":"Teixeira","given":"Elico"},{"family":"Fritze","given":"Matthew"},{"family":"Bertolini","given":"Francesco"},{"family":"Marinescu","given":"Liana-Eleonora"},{"family":"Bölle","given":"Martin"},{"family":"Paulus","given":"Dominik"},{"family":"Gupta","given":"Khyatti"},{"family":"Latkar","given":"Tejasi"},{"family":"Chang","given":"Max"},{"family":"Sanders","given":"Jason"},{"family":"Wilson","given":"Roopa"},{"family":"Wu","given":"Xuewei"},{"family":"Tan","given":"Yi-Xuan"},{"family":"Thiet","given":"Lam Nguyen"},{"family":"Doshi","given":"Tulsee"},{"family":"Lall","given":"Sid"},{"family":"Mishra","given":"Swaroop"},{"family":"Chen","given":"Wanming"},{"family":"Luong","given":"Thang"},{"family":"Benjamin","given":"Seth"},{"family":"Lee","given":"Jasmine"},{"family":"Andrejczuk","given":"Ewa"},{"family":"Rabiej","given":"Dominik"},{"family":"Ranjan","given":"Vipul"},{"family":"Styrc","given":"Krzysztof"},{"family":"Yin","given":"Pengcheng"},{"family":"Simon","given":"Jon"},{"family":"Harriott","given":"Malcolm Rose"},{"family":"Bansal","given":"Mudit"},{"family":"Robsky","given":"Alexei"},{"family":"Bacon","given":"Geoff"},{"family":"Greene","given":"David"},{"family":"Mirylenka","given":"Daniil"},{"family":"Zhou","given":"Chen"},{"family":"Sarvana","given":"Obaid"},{"family":"Goyal","given":"Abhimanyu"},{"family":"Andermatt","given":"Samuel"},{"family":"Siegler","given":"Patrick"},{"family":"Horn","given":"Ben"},{"family":"Israel","given":"Assaf"},{"family":"Pongetti","given":"Francesco"},{"family":"Chen","given":"Chih-Wei \"Louis\""},{"family":"Selvatici","given":"Marco"},{"family":"Silva","given":"Pedro"},{"family":"Wang","given":"Kathie"},{"family":"Tolins","given":"Jackson"},{"family":"Guu","given":"Kelvin"},{"family":"Yogev","given":"Roey"},{"family":"Cai","given":"Xiaochen"},{"family":"Agostini","given":"Alessandro"},{"family":"Shah","given":"Maulik"},{"family":"Nguyen","given":"Hung"},{"family":"Donnaile","given":"Noah Ó"},{"family":"Pereira","given":"Sébastien"},{"family":"Friso","given":"Linda"},{"family":"Stambler","given":"Adam"},{"family":"Kurzrok","given":"Adam"},{"family":"Kuang","given":"Chenkai"},{"family":"Romanikhin","given":"Yan"},{"family":"Geller","given":"Mark"},{"family":"Yan","given":"Z. J."},{"family":"Jang","given":"Kane"},{"family":"Lee","given":"Cheng-Chun"},{"family":"Fica","given":"Wojciech"},{"family":"Malmi","given":"Eric"},{"family":"Tan","given":"Qijun"},{"family":"Banica","given":"Dan"},{"family":"Balle","given":"Daniel"},{"family":"Pham","given":"Ryan"},{"family":"Huang","given":"Yanping"},{"family":"Avram","given":"Diana"},{"family":"Shi","given":"Hongzhi"},{"family":"Singh","given":"Jasjot"},{"family":"Hidey","given":"Chris"},{"family":"Ahuja","given":"Niharika"},{"family":"Saxena","given":"Pranab"},{"family":"Dooley","given":"Dan"},{"family":"Potharaju","given":"Srividya Pranavi"},{"family":"O'Neill","given":"Eileen"},{"family":"Gokulchandran","given":"Anand"},{"family":"Foley","given":"Ryan"},{"family":"Zhao","given":"Kai"},{"family":"Dusenberry","given":"Mike"},{"family":"Liu","given":"Yuan"},{"family":"Mehta","given":"Pulkit"},{"family":"Kotikalapudi","given":"Ragha"},{"family":"Safranek-Shrader","given":"Chalence"},{"family":"Goodman","given":"Andrew"},{"family":"Kessinger","given":"Joshua"},{"family":"Globen","given":"Eran"},{"family":"Kolhar","given":"Prateek"},{"family":"Gorgolewski","given":"Chris"},{"family":"Ibrahim","given":"Ali"},{"family":"Song","given":"Yang"},{"family":"Eichenbaum","given":"Ali"},{"family":"Brovelli","given":"Thomas"},{"family":"Potluri","given":"Sahitya"},{"family":"Lahoti","given":"Preethi"},{"family":"Baetu","given":"Cip"},{"family":"Ghorbani","given":"Ali"},{"family":"Chen","given":"Charles"},{"family":"Crawford","given":"Andy"},{"family":"Pal","given":"Shalini"},{"family":"Sridhar","given":"Mukund"},{"family":"Gurita","given":"Petru"},{"family":"Mujika","given":"Asier"},{"family":"Petrovski","given":"Igor"},{"family":"Cedoz","given":"Pierre-Louis"},{"family":"Li","given":"Chenmei"},{"family":"Chen","given":"Shiyuan"},{"family":"Santo","given":"Niccolò Dal"},{"family":"Goyal","given":"Siddharth"},{"family":"Punjabi","given":"Jitesh"},{"family":"Kappaganthu","given":"Karthik"},{"family":"Kwak","given":"Chester"},{"family":"LV","given":"Pallavi"},{"family":"Velury","given":"Sarmishta"},{"family":"Choudhury","given":"Himadri"},{"family":"Hall","given":"Jamie"},{"family":"Shah","given":"Premal"},{"family":"Figueira","given":"Ricardo"},{"family":"Thomas","given":"Matt"},{"family":"Lu","given":"Minjie"},{"family":"Zhou","given":"Ting"},{"family":"Kumar","given":"Chintu"},{"family":"Jurdi","given":"Thomas"},{"family":"Chikkerur","given":"Sharat"},{"family":"Ma","given":"Yenai"},{"family":"Yu","given":"Adams"},{"family":"Kwak","given":"Soo"},{"family":"Ähdel","given":"Victor"},{"family":"Rajayogam","given":"Sujeevan"},{"family":"Choma","given":"Travis"},{"family":"Liu","given":"Fei"},{"family":"Barua","given":"Aditya"},{"family":"Ji","given":"Colin"},{"family":"Park","given":"Ji Ho"},{"family":"Hellendoorn","given":"Vincent"},{"family":"Bailey","given":"Alex"},{"family":"Bilal","given":"Taylan"},{"family":"Zhou","given":"Huanjie"},{"family":"Khatir","given":"Mehrdad"},{"family":"Sutton","given":"Charles"},{"family":"Rzadkowski","given":"Wojciech"},{"family":"Macintosh","given":"Fiona"},{"family":"Shagin","given":"Konstantin"},{"family":"Medina","given":"Paul"},{"family":"Liang","given":"Chen"},{"family":"Zhou","given":"Jinjing"},{"family":"Shah","given":"Pararth"},{"family":"Bi","given":"Yingying"},{"family":"Dankovics","given":"Attila"},{"family":"Banga","given":"Shipra"},{"family":"Lehmann","given":"Sabine"},{"family":"Bredesen","given":"Marissa"},{"family":"Lin","given":"Zifan"},{"family":"Hoffmann","given":"John Eric"},{"family":"Lai","given":"Jonathan"},{"family":"Chung","given":"Raynald"},{"family":"Yang","given":"Kai"},{"family":"Balani","given":"Nihal"},{"family":"Bražinskas","given":"Arthur"},{"family":"Sozanschi","given":"Andrei"},{"family":"Hayes","given":"Matthew"},{"family":"Alcalde","given":"Héctor Fernández"},{"family":"Makarov","given":"Peter"},{"family":"Chen","given":"Will"},{"family":"Stella","given":"Antonio"},{"family":"Snijders","given":"Liselotte"},{"family":"Mandl","given":"Michael"},{"family":"Kärrman","given":"Ante"},{"family":"Nowak","given":"Paweł"},{"family":"Wu","given":"Xinyi"},{"family":"Dyck","given":"Alex"},{"family":"Vaidyanathan","given":"Krishnan"},{"family":"R","given":"Raghavender"},{"family":"Mallet","given":"Jessica"},{"family":"Rudominer","given":"Mitch"},{"family":"Johnston","given":"Eric"},{"family":"Mittal","given":"Sushil"},{"family":"Udathu","given":"Akhil"},{"family":"Christensen","given":"Janara"},{"family":"Verma","given":"Vishal"},{"family":"Irving","given":"Zach"},{"family":"Santucci","given":"Andreas"},{"family":"Elsayed","given":"Gamaleldin"},{"family":"Davoodi","given":"Elnaz"},{"family":"Georgiev","given":"Marin"},{"family":"Tenney","given":"Ian"},{"family":"Hua","given":"Nan"},{"family":"Cideron","given":"Geoffrey"},{"family":"Leurent","given":"Edouard"},{"family":"Alnahlawi","given":"Mahmoud"},{"family":"Georgescu","given":"Ionut"},{"family":"Wei","given":"Nan"},{"family":"Zheng","given":"Ivy"},{"family":"Scandinaro","given":"Dylan"},{"family":"Jiang","given":"Heinrich"},{"family":"Snoek","given":"Jasper"},{"family":"Sundararajan","given":"Mukund"},{"family":"Wang","given":"Xuezhi"},{"family":"Ontiveros","given":"Zack"},{"family":"Karo","given":"Itay"},{"family":"Cole","given":"Jeremy"},{"family":"Rajashekhar","given":"Vinu"},{"family":"Tumeh","given":"Lara"},{"family":"Ben-David","given":"Eyal"},{"family":"Jain","given":"Rishub"},{"family":"Uesato","given":"Jonathan"},{"family":"Datta","given":"Romina"},{"family":"Bunyan","given":"Oskar"},{"family":"Wu","given":"Shimu"},{"family":"Zhang","given":"John"},{"family":"Stanczyk","given":"Piotr"},{"family":"Zhang","given":"Ye"},{"family":"Steiner","given":"David"},{"family":"Naskar","given":"Subhajit"},{"family":"Azzam","given":"Michael"},{"family":"Johnson","given":"Matthew"},{"family":"Paszke","given":"Adam"},{"family":"Chiu","given":"Chung-Cheng"},{"family":"Elias","given":"Jaume Sanchez"},{"family":"Mohiuddin","given":"Afroz"},{"family":"Muhammad","given":"Faizan"},{"family":"Miao","given":"Jin"},{"family":"Lee","given":"Andrew"},{"family":"Vieillard","given":"Nino"},{"family":"Park","given":"Jane"},{"family":"Zhang","given":"Jiageng"},{"family":"Stanway","given":"Jeff"},{"family":"Garmon","given":"Drew"},{"family":"Karmarkar","given":"Abhijit"},{"family":"Dong","given":"Zhe"},{"family":"Lee","given":"Jong"},{"family":"Kumar","given":"Aviral"},{"family":"Zhou","given":"Luowei"},{"family":"Evens","given":"Jonathan"},{"family":"Isaac","given":"William"},{"family":"Irving","given":"Geoffrey"},{"family":"Loper","given":"Edward"},{"family":"Fink","given":"Michael"},{"family":"Arkatkar","given":"Isha"},{"family":"Chen","given":"Nanxin"},{"family":"Shafran","given":"Izhak"},{"family":"Petrychenko","given":"Ivan"},{"family":"Chen","given":"Zhe"},{"family":"Jia","given":"Johnson"},{"family":"Levskaya","given":"Anselm"},{"family":"Zhu","given":"Zhenkai"},{"family":"Grabowski","given":"Peter"},{"family":"Mao","given":"Yu"},{"family":"Magni","given":"Alberto"},{"family":"Yao","given":"Kaisheng"},{"family":"Snaider","given":"Javier"},{"family":"Casagrande","given":"Norman"},{"family":"Palmer","given":"Evan"},{"family":"Suganthan","given":"Paul"},{"family":"Castaño","given":"Alfonso"},{"family":"Giannoumis","given":"Irene"},{"family":"Kim","given":"Wooyeol"},{"family":"Rybiński","given":"Mikołaj"},{"family":"Sreevatsa","given":"Ashwin"},{"family":"Prendki","given":"Jennifer"},{"family":"Soergel","given":"David"},{"family":"Goedeckemeyer","given":"Adrian"},{"family":"Gierke","given":"Willi"},{"family":"Jafari","given":"Mohsen"},{"family":"Gaba","given":"Meenu"},{"family":"Wiesner","given":"Jeremy"},{"family":"Wright","given":"Diana Gage"},{"family":"Wei","given":"Yawen"},{"family":"Vashisht","given":"Harsha"},{"family":"Kulizhskaya","given":"Yana"},{"family":"Hoover","given":"Jay"},{"family":"Le","given":"Maigo"},{"family":"Li","given":"Lu"},{"family":"Iwuanyanwu","given":"Chimezie"},{"family":"Liu","given":"Lu"},{"family":"Ramirez","given":"Kevin"},{"family":"Khorlin","given":"Andrey"},{"family":"Cui","given":"Albert"},{"family":"LIN","given":"Tian"},{"family":"Wu","given":"Marcus"},{"family":"Aguilar","given":"Ricardo"},{"family":"Pallo","given":"Keith"},{"family":"Chakladar","given":"Abhishek"},{"family":"Perng","given":"Ginger"},{"family":"Abellan","given":"Elena Allica"},{"family":"Zhang","given":"Mingyang"},{"family":"Dasgupta","given":"Ishita"},{"family":"Kushman","given":"Nate"},{"family":"Penchev","given":"Ivo"},{"family":"Repina","given":"Alena"},{"family":"Wu","given":"Xihui"},{"family":"Weide","given":"Tom","dropping-particle":"van der"},{"family":"Ponnapalli","given":"Priya"},{"family":"Kaplan","given":"Caroline"},{"family":"Simsa","given":"Jiri"},{"family":"Li","given":"Shuangfeng"},{"family":"Dousse","given":"Olivier"},{"family":"Yang","given":"Fan"},{"family":"Piper","given":"Jeff"},{"family":"Ie","given":"Nathan"},{"family":"Pasumarthi","given":"Rama"},{"family":"Lintz","given":"Nathan"},{"family":"Vijayakumar","given":"Anitha"},{"family":"Andor","given":"Daniel"},{"family":"Valenzuela","given":"Pedro"},{"family":"Lui","given":"Minnie"},{"family":"Paduraru","given":"Cosmin"},{"family":"Peng","given":"Daiyi"},{"family":"Lee","given":"Katherine"},{"family":"Zhang","given":"Shuyuan"},{"family":"Greene","given":"Somer"},{"family":"Nguyen","given":"Duc Dung"},{"family":"Kurylowicz","given":"Paula"},{"family":"Hardin","given":"Cassidy"},{"family":"Dixon","given":"Lucas"},{"family":"Janzer","given":"Lili"},{"family":"Choo","given":"Kiam"},{"family":"Feng","given":"Ziqiang"},{"family":"Zhang","given":"Biao"},{"family":"Singhal","given":"Achintya"},{"family":"Du","given":"Dayou"},{"family":"McKinnon","given":"Dan"},{"family":"Antropova","given":"Natasha"},{"family":"Bolukbasi","given":"Tolga"},{"family":"Keller","given":"Orgad"},{"family":"Reid","given":"David"},{"family":"Finchelstein","given":"Daniel"},{"family":"Raad","given":"Maria Abi"},{"family":"Crocker","given":"Remi"},{"family":"Hawkins","given":"Peter"},{"family":"Dadashi","given":"Robert"},{"family":"Gaffney","given":"Colin"},{"family":"Franko","given":"Ken"},{"family":"Bulanova","given":"Anna"},{"family":"Leblond","given":"Rémi"},{"family":"Chung","given":"Shirley"},{"family":"Askham","given":"Harry"},{"family":"Cobo","given":"Luis C."},{"family":"Xu","given":"Kelvin"},{"family":"Fischer","given":"Felix"},{"family":"Xu","given":"Jun"},{"family":"Sorokin","given":"Christina"},{"family":"Alberti","given":"Chris"},{"family":"Lin","given":"Chu-Cheng"},{"family":"Evans","given":"Colin"},{"family":"Dimitriev","given":"Alek"},{"family":"Forbes","given":"Hannah"},{"family":"Banarse","given":"Dylan"},{"family":"Tung","given":"Zora"},{"family":"Omernick","given":"Mark"},{"family":"Bishop","given":"Colton"},{"family":"Sterneck","given":"Rachel"},{"family":"Jain","given":"Rohan"},{"family":"Xia","given":"Jiawei"},{"family":"Amid","given":"Ehsan"},{"family":"Piccinno","given":"Francesco"},{"family":"Wang","given":"Xingyu"},{"family":"Banzal","given":"Praseem"},{"family":"Mankowitz","given":"Daniel J."},{"family":"Polozov","given":"Alex"},{"family":"Krakovna","given":"Victoria"},{"family":"Brown","given":"Sasha"},{"family":"Bateni","given":"MohammadHossein"},{"family":"Duan","given":"Dennis"},{"family":"Firoiu","given":"Vlad"},{"family":"Thotakuri","given":"Meghana"},{"family":"Natan","given":"Tom"},{"family":"Geist","given":"Matthieu"},{"family":"Girgin","given":"Ser","dropping-particle":"tan"},{"family":"Li","given":"Hui"},{"family":"Ye","given":"Jiayu"},{"family":"Roval","given":"Ofir"},{"family":"Tojo","given":"Reiko"},{"family":"Kwong","given":"Michael"},{"family":"Lee-Thorp","given":"James"},{"family":"Yew","given":"Christopher"},{"family":"Sinopalnikov","given":"Danila"},{"family":"Ramos","given":"Sabela"},{"family":"Mellor","given":"John"},{"family":"Sharma","given":"Abhishek"},{"family":"Wu","given":"Kathy"},{"family":"Miller","given":"David"},{"family":"Sonnerat","given":"Nicolas"},{"family":"Vnukov","given":"Denis"},{"family":"Greig","given":"Rory"},{"family":"Beattie","given":"Jennifer"},{"family":"Caveness","given":"Emily"},{"family":"Bai","given":"Libin"},{"family":"Eisenschlos","given":"Julian"},{"family":"Korchemniy","given":"Alex"},{"family":"Tsai","given":"Tomy"},{"family":"Jasarevic","given":"Mimi"},{"family":"Kong","given":"Weize"},{"family":"Dao","given":"Phuong"},{"family":"Zheng","given":"Zeyu"},{"family":"Liu","given":"Frederick"},{"family":"Yang","given":"Fan"},{"family":"Zhu","given":"Rui"},{"family":"Teh","given":"Tian Huey"},{"family":"Sanmiya","given":"Jason"},{"family":"Gladchenko","given":"Evgeny"},{"family":"Trdin","given":"Nejc"},{"family":"Toyama","given":"Daniel"},{"family":"Rosen","given":"Evan"},{"family":"Tavakkol","given":"Sasan"},{"family":"Xue","given":"Linting"},{"family":"Elkind","given":"Chen"},{"family":"Woodman","given":"Oliver"},{"family":"Carpenter","given":"John"},{"family":"Papamakarios","given":"George"},{"family":"Kemp","given":"Rupert"},{"family":"Kafle","given":"Sushant"},{"family":"Grunina","given":"Tanya"},{"family":"Sinha","given":"Rishika"},{"family":"Talbert","given":"Alice"},{"family":"Wu","given":"Diane"},{"family":"Owusu-Afriyie","given":"Denese"},{"family":"Du","given":"Cosmo"},{"family":"Thornton","given":"Chloe"},{"family":"Pont-Tuset","given":"Jordi"},{"family":"Narayana","given":"Pradyumna"},{"family":"Li","given":"Jing"},{"family":"Fatehi","given":"Saaber"},{"family":"Wieting","given":"John"},{"family":"Ajmeri","given":"Omar"},{"family":"Uria","given":"Benigno"},{"family":"Ko","given":"Yeongil"},{"family":"Knight","given":"Laura"},{"family":"Héliou","given":"Amélie"},{"family":"Niu","given":"Ning"},{"family":"Gu","given":"Shane"},{"family":"Pang","given":"Chenxi"},{"family":"Li","given":"Yeqing"},{"family":"Levine","given":"Nir"},{"family":"Stolovich","given":"Ariel"},{"family":"Santamaria-Fernandez","given":"Rebeca"},{"family":"Goenka","given":"Sonam"},{"family":"Yustalim","given":"Wenny"},{"family":"Strudel","given":"Robin"},{"family":"Elqursh","given":"Ali"},{"family":"Deck","given":"Charlie"},{"family":"Lee","given":"Hyo"},{"family":"Li","given":"Zonglin"},{"family":"Levin","given":"Kyle"},{"family":"Hoffmann","given":"Raphael"},{"family":"Holtmann-Rice","given":"Dan"},{"family":"Bachem","given":"Olivier"},{"family":"Arora","given":"Sho"},{"family":"Koh","given":"Christy"},{"family":"Yeganeh","given":"Soheil Hassas"},{"family":"Põder","given":"Siim"},{"family":"Tariq","given":"Mukarram"},{"family":"Sun","given":"Yanhua"},{"family":"Ionita","given":"Lucian"},{"family":"Seyedhosseini","given":"Mojtaba"},{"family":"Tafti","given":"Pouya"},{"family":"Liu","given":"Zhiyu"},{"family":"Gulati","given":"Anmol"},{"family":"Liu","given":"Jasmine"},{"family":"Ye","given":"Xinyu"},{"family":"Chrzaszcz","given":"Bart"},{"family":"Wang","given":"Lily"},{"family":"Sethi","given":"Nikhil"},{"family":"Li","given":"Tianrun"},{"family":"Brown","given":"Ben"},{"family":"Singh","given":"Shreya"},{"family":"Fan","given":"Wei"},{"family":"Parisi","given":"Aaron"},{"family":"Stanton","given":"Joe"},{"family":"Koverkathu","given":"Vinod"},{"family":"Choquette-Choo","given":"Christopher A."},{"family":"Li","given":"Yunjie"},{"family":"Lu","given":"T. J."},{"family":"Ittycheriah","given":"Abe"},{"family":"Shroff","given":"Prakash"},{"family":"Varadarajan","given":"Mani"},{"family":"Bahargam","given":"Sanaz"},{"family":"Willoughby","given":"Rob"},{"family":"Gaddy","given":"David"},{"family":"Desjardins","given":"Guillaume"},{"family":"Cornero","given":"Marco"},{"family":"Robenek","given":"Brona"},{"family":"Mittal","given":"Bhavishya"},{"family":"Albrecht","given":"Ben"},{"family":"Shenoy","given":"Ashish"},{"family":"Moiseev","given":"Fedor"},{"family":"Jacobsson","given":"Henrik"},{"family":"Ghaffarkhah","given":"Alireza"},{"family":"Rivière","given":"Morgane"},{"family":"Walton","given":"Alanna"},{"family":"Crepy","given":"Clément"},{"family":"Parrish","given":"Alicia"},{"family":"Zhou","given":"Zongwei"},{"family":"Farabet","given":"Clement"},{"family":"Radebaugh","given":"Carey"},{"family":"Srinivasan","given":"Praveen"},{"family":"Salm","given":"Claudia","dropping-particle":"van der"},{"family":"Fidjeland","given":"Andreas"},{"family":"Scellato","given":"Salvatore"},{"family":"Latorre-Chimoto","given":"Eri"},{"family":"Klimczak-Plucińska","given":"Hanna"},{"family":"Bridson","given":"David"},{"family":"Cesare","given":"Dario","dropping-particle":"de"},{"family":"Hudson","given":"Tom"},{"family":"Mendolicchio","given":"Piermaria"},{"family":"Walker","given":"Lexi"},{"family":"Morris","given":"Alex"},{"family":"Mauger","given":"Matthew"},{"family":"Guseynov","given":"Alexey"},{"family":"Reid","given":"Alison"},{"family":"Odoom","given":"Seth"},{"family":"Loher","given":"Lucia"},{"family":"Cotruta","given":"Victor"},{"family":"Yenugula","given":"Madhavi"},{"family":"Grewe","given":"Dominik"},{"family":"Petrushkina","given":"Anastasia"},{"family":"Duerig","given":"Tom"},{"family":"Sanchez","given":"Antonio"},{"family":"Yadlowsky","given":"Steve"},{"family":"Shen","given":"Amy"},{"family":"Globerson","given":"Amir"},{"family":"Webb","given":"Lynette"},{"family":"Dua","given":"Sahil"},{"family":"Li","given":"Dong"},{"family":"Bhupatiraju","given":"Surya"},{"family":"Hurt","given":"Dan"},{"family":"Qureshi","given":"Haroon"},{"family":"Agarwal","given":"Ananth"},{"family":"Shani","given":"Tomer"},{"family":"Eyal","given":"Matan"},{"family":"Khare","given":"Anuj"},{"family":"Belle","given":"Shreyas Rammohan"},{"family":"Wang","given":"Lei"},{"family":"Tekur","given":"Chetan"},{"family":"Kale","given":"Mihir Sanjay"},{"family":"Wei","given":"Jinliang"},{"family":"Sang","given":"Ruoxin"},{"family":"Saeta","given":"Brennan"},{"family":"Liechty","given":"Tyler"},{"family":"Sun","given":"Yi"},{"family":"Zhao","given":"Yao"},{"family":"Lee","given":"Stephan"},{"family":"Nayak","given":"Pandu"},{"family":"Fritz","given":"Doug"},{"family":"Vuyyuru","given":"Manish Reddy"},{"family":"Aslanides","given":"John"},{"family":"Vyas","given":"Nidhi"},{"family":"Wicke","given":"Martin"},{"family":"Ma","given":"Xiao"},{"family":"Eltyshev","given":"Evgenii"},{"family":"Martin","given":"Nina"},{"family":"Cate","given":"Hardie"},{"family":"Manyika","given":"James"},{"family":"Amiri","given":"Keyvan"},{"family":"Kim","given":"Yelin"},{"family":"Xiong","given":"Xi"},{"family":"Kang","given":"Kai"},{"family":"Luisier","given":"Florian"},{"family":"Tripuraneni","given":"Nilesh"},{"family":"Madras","given":"David"},{"family":"Guo","given":"Mandy"},{"family":"Waters","given":"Austin"},{"family":"Wang","given":"Oliver"},{"family":"Ainslie","given":"Joshua"},{"family":"Baldridge","given":"Jason"},{"family":"Zhang","given":"Han"},{"family":"Pruthi","given":"Garima"},{"family":"Bauer","given":"Jakob"},{"family":"Yang","given":"Feng"},{"family":"Mansour","given":"Riham"},{"family":"Gelman","given":"Jason"},{"family":"Xu","given":"Yang"},{"family":"Polovets","given":"George"},{"family":"Liu","given":"Ji"},{"family":"Cai","given":"Honglong"},{"family":"Chen","given":"Warren"},{"family":"Sheng","given":"XiangHai"},{"family":"Xue","given":"Emily"},{"family":"Ozair","given":"Sherjil"},{"family":"Angermueller","given":"Christof"},{"family":"Li","given":"Xiaowei"},{"family":"Sinha","given":"Anoop"},{"family":"Wang","given":"Weiren"},{"family":"Wiesinger","given":"Julia"},{"family":"Koukoumidis","given":"Emmanouil"},{"family":"Tian","given":"Yuan"},{"family":"Iyer","given":"Anand"},{"family":"Gurumurthy","given":"Madhu"},{"family":"Goldenson","given":"Mark"},{"family":"Shah","given":"Parashar"},{"family":"Blake","given":"M. K."},{"family":"Yu","given":"Hongkun"},{"family":"Urbanowicz","given":"Anthony"},{"family":"Palomaki","given":"Jennimaria"},{"family":"Fernando","given":"Chrisantha"},{"family":"Durden","given":"Ken"},{"family":"Mehta","given":"Harsh"},{"family":"Momchev","given":"Nikola"},{"family":"Rahimtoroghi","given":"Elahe"},{"family":"Georgaki","given":"Maria"},{"family":"Raul","given":"Amit"},{"family":"Ruder","given":"Sebastian"},{"family":"Redshaw","given":"Morgan"},{"family":"Lee","given":"Jinhyuk"},{"family":"Zhou","given":"Denny"},{"family":"Jalan","given":"Komal"},{"family":"Li","given":"Dinghua"},{"family":"Hechtman","given":"Blake"},{"family":"Schuh","given":"Parker"},{"family":"Nasr","given":"Milad"},{"family":"Milan","given":"Kieran"},{"family":"Mikulik","given":"Vladimir"},{"family":"Franco","given":"Juliana"},{"family":"Green","given":"Tim"},{"family":"Nguyen","given":"Nam"},{"family":"Kelley","given":"Joe"},{"family":"Mahendru","given":"Aroma"},{"family":"Hu","given":"Andrea"},{"family":"Howland","given":"Joshua"},{"family":"Vargas","given":"Ben"},{"family":"Hui","given":"Jeffrey"},{"family":"Bansal","given":"Kshitij"},{"family":"Rao","given":"Vikram"},{"family":"Ghiya","given":"Rakesh"},{"family":"Wang","given":"Emma"},{"family":"Ye","given":"Ke"},{"family":"Sarr","given":"Jean Michel"},{"family":"Preston","given":"Melanie Moranski"},{"family":"Elish","given":"Madeleine"},{"family":"Li","given":"Steve"},{"family":"Kaku","given":"Aakash"},{"family":"Gupta","given":"Jigar"},{"family":"Pasupat","given":"Ice"},{"family":"Juan","given":"Da-Cheng"},{"family":"Someswar","given":"Milan"},{"family":"M","given":"Tejvi"},{"family":"Chen","given":"Xinyun"},{"family":"Amini","given":"Aida"},{"family":"Fabrikant","given":"Alex"},{"family":"Chu","given":"Eric"},{"family":"Dong","given":"Xuanyi"},{"family":"Muthal","given":"Amruta"},{"family":"Buthpitiya","given":"Senaka"},{"family":"Jauhari","given":"Sarthak"},{"family":"Hua","given":"Nan"},{"family":"Khandelwal","given":"Urvashi"},{"family":"Hitron","given":"Ayal"},{"family":"Ren","given":"Jie"},{"family":"Rinaldi","given":"Larissa"},{"family":"Drath","given":"Shahar"},{"family":"Dabush","given":"Avigail"},{"family":"Jiang","given":"Nan-Jiang"},{"family":"Godhia","given":"Harshal"},{"family":"Sachs","given":"Uli"},{"family":"Chen","given":"Anthony"},{"family":"Fan","given":"Yicheng"},{"family":"Taitelbaum","given":"Hagai"},{"family":"Noga","given":"Hila"},{"family":"Dai","given":"Zhuyun"},{"family":"Wang","given":"James"},{"family":"Liang","given":"Chen"},{"family":"Hamer","given":"Jenny"},{"family":"Ferng","given":"Chun-Sung"},{"family":"Elkind","given":"Chenel"},{"family":"Atias","given":"Aviel"},{"family":"Lee","given":"Paulina"},{"family":"Listík","given":"Vít"},{"family":"Carlen","given":"Mathias"},{"family":"Kerkhof","given":"Jan","dropping-particle":"van de"},{"family":"Pikus","given":"Marcin"},{"family":"Zaher","given":"Krunoslav"},{"family":"Müller","given":"Paul"},{"family":"Zykova","given":"Sasha"},{"family":"Stefanec","given":"Richard"},{"family":"Gatsko","given":"Vitaly"},{"family":"Hirnschall","given":"Christoph"},{"family":"Sethi","given":"Ashwin"},{"family":"Xu","given":"Xingyu Federico"},{"family":"Ahuja","given":"Chetan"},{"family":"Tsai","given":"Beth"},{"family":"Stefanoiu","given":"Anca"},{"family":"Feng","given":"Bo"},{"family":"Dhandhania","given":"Keshav"},{"family":"Katyal","given":"Manish"},{"family":"Gupta","given":"Akshay"},{"family":"Parulekar","given":"Atharva"},{"family":"Pitta","given":"Divya"},{"family":"Zhao","given":"Jing"},{"family":"Bhatia","given":"Vivaan"},{"family":"Bhavnani","given":"Yashodha"},{"family":"Alhadlaq","given":"Omar"},{"family":"Li","given":"Xiaolin"},{"family":"Danenberg","given":"Peter"},{"family":"Tu","given":"Dennis"},{"family":"Pine","given":"Alex"},{"family":"Filippova","given":"Vera"},{"family":"Ghosh","given":"Abhipso"},{"family":"Limonchik","given":"Ben"},{"family":"Urala","given":"Bhargava"},{"family":"Lanka","given":"Chaitanya Krishna"},{"family":"Clive","given":"Derik"},{"family":"Sun","given":"Yi"},{"family":"Li","given":"Edward"},{"family":"Wu","given":"Hao"},{"family":"Hongtongsak","given":"Kevin"},{"family":"Li","given":"Ianna"},{"family":"Thakkar","given":"Kalind"},{"family":"Omarov","given":"Kuanysh"},{"family":"Majmundar","given":"Kushal"},{"family":"Alverson","given":"Michael"},{"family":"Kucharski","given":"Michael"},{"family":"Patel","given":"Mohak"},{"family":"Jain","given":"Mudit"},{"family":"Zabelin","given":"Maksim"},{"family":"Pelagatti","given":"Paolo"},{"family":"Kohli","given":"Rohan"},{"family":"Kumar","given":"Saurabh"},{"family":"Kim","given":"Joseph"},{"family":"Sankar","given":"Swetha"},{"family":"Shah","given":"Vineet"},{"family":"Ramachandruni","given":"Lakshmi"},{"family":"Zeng","given":"Xiangkai"},{"family":"Bariach","given":"Ben"},{"family":"Weidinger","given":"Laura"},{"family":"Vu","given":"Tu"},{"family":"Andreev","given":"Alek"},{"family":"He","given":"Antoine"},{"family":"Hui","given":"Kevin"},{"family":"Kashem","given":"Sheleem"},{"family":"Subramanya","given":"Amar"},{"family":"Hsiao","given":"Sissie"},{"family":"Hassabis","given":"Demis"},{"family":"Kavukcuoglu","given":"Koray"},{"family":"Sadovsky","given":"Adam"},{"family":"Le","given":"Quoc"},{"family":"Strohman","given":"Trevor"},{"family":"Wu","given":"Yonghui"},{"family":"Petrov","given":"Slav"},{"family":"Dean","given":"Jeffrey"},{"family":"Vinyals","given":"Oriol"}],"citation-key":"teamGeminiFamilyHighly2024","DOI":"10.48550/arXiv.2312.11805","issued":{"date-parts":[["2024",6,17]]},"number":"arXiv:2312.11805","publisher":"arXiv","source":"arXiv.org","title":"Gemini: A Family of Highly Capable Multimodal Models","title-short":"Gemini","type":"article","URL":"http://arxiv.org/abs/2312.11805"},
  {"id":"tranRARERetrievalAugmentedReasoning2024","abstract":"This work introduces RARE (Retrieval-Augmented Reasoning Enhancement), a versatile extension to the mutual reasoning framework (rStar), aimed at enhancing reasoning accuracy and factual integrity across large language models (LLMs) for complex, knowledge-intensive tasks such as commonsense and medical reasoning. RARE incorporates two innovative actions within the Monte Carlo Tree Search (MCTS) framework: A6, which generates search queries based on the initial problem statement, performs information retrieval using those queries, and augments reasoning with the retrieved data to formulate the final answer; and A7, which leverages information retrieval specifically for generated sub-questions and re-answers these sub-questions with the relevant contextual information. Additionally, a Retrieval-Augmented Factuality Scorer is proposed to replace the original discriminator, prioritizing reasoning paths that meet high standards of factuality. Experimental results with LLaMA 3.1 show that RARE enables open-source LLMs to achieve competitive performance with top open-source models like GPT-4 and GPT-4o. This research establishes RARE as a scalable solution for improving LLMs in domains where logical coherence and factual integrity are critical.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Tran","given":"Hieu"},{"family":"Yao","given":"Zonghai"},{"family":"Wang","given":"Junda"},{"family":"Zhang","given":"Yifan"},{"family":"Yang","given":"Zhichao"},{"family":"Yu","given":"Hong"}],"citation-key":"tranRARERetrievalAugmentedReasoning2024","DOI":"10.48550/arXiv.2412.02830","issued":{"date-parts":[["2024",12,9]]},"number":"arXiv:2412.02830","publisher":"arXiv","source":"arXiv.org","title":"RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models","title-short":"RARE","type":"article","URL":"http://arxiv.org/abs/2412.02830"},
  {"id":"vaswaniAttentionAllYou2023","abstract":"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Vaswani","given":"Ashish"},{"family":"Shazeer","given":"Noam"},{"family":"Parmar","given":"Niki"},{"family":"Uszkoreit","given":"Jakob"},{"family":"Jones","given":"Llion"},{"family":"Gomez","given":"Aidan N."},{"family":"Kaiser","given":"Lukasz"},{"family":"Polosukhin","given":"Illia"}],"citation-key":"vaswaniAttentionAllYou2023","DOI":"10.48550/arXiv.1706.03762","issued":{"date-parts":[["2023",8,2]]},"number":"arXiv:1706.03762","publisher":"arXiv","source":"arXiv.org","title":"Attention Is All You Need","type":"article","URL":"http://arxiv.org/abs/1706.03762"},
  {"id":"wangCanLLMsConvert2024","abstract":"Graphs are ubiquitous data structures found in numerous real-world applications, such as drug discovery, recommender systems, and social network analysis. Graph neural networks (GNNs) have become a popular tool to learn node embeddings through message passing on these structures. However, a significant challenge arises when applying GNNs to multiple graphs with different feature spaces, as existing GNN architectures are not designed for cross-graph feature alignment. To address this, recent approaches introduce text-attributed graphs, where each node is associated with a textual description, enabling the use of a shared textual encoder to project nodes from different graphs into a unified feature space. While promising, this method relies heavily on the availability of text-attributed data, which can be difficult to obtain in practice. To bridge this gap, we propose a novel method named Topology-Aware Node description Synthesis (TANS), which leverages large language models (LLMs) to automatically convert existing graphs into text-attributed graphs. The key idea is to integrate topological information with each node's properties, enhancing the LLMs' ability to explain how graph topology influences node semantics. We evaluate our TANS on text-rich, text-limited, and text-free graphs, demonstrating that it enables a single GNN to operate across diverse graphs. Notably, on text-free graphs, our method significantly outperforms existing approaches that manually design node features, showcasing the potential of LLMs for preprocessing graph-structured data, even in the absence of textual information. The code and data are available at https://github.com/Zehong-Wang/TANS.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Wang","given":"Zehong"},{"family":"Liu","given":"Sidney"},{"family":"Zhang","given":"Zheyuan"},{"family":"Ma","given":"Tianyi"},{"family":"Zhang","given":"Chuxu"},{"family":"Ye","given":"Yanfang"}],"citation-key":"wangCanLLMsConvert2024","DOI":"10.48550/arXiv.2412.10136","issued":{"date-parts":[["2024",12,13]]},"number":"arXiv:2412.10136","publisher":"arXiv","source":"arXiv.org","title":"Can LLMs Convert Graphs to Text-Attributed Graphs?","type":"article","URL":"http://arxiv.org/abs/2412.10136"},
  {"id":"wangWhenPrecisionMeets2024","abstract":"Extending context window sizes allows large language models (LLMs) to process longer sequences and handle more complex tasks. Rotary Positional Embedding (RoPE) has become the de facto standard due to its relative positional encoding properties that benefit long-context training. However, we observe that using RoPE with BFloat16 format results in numerical issues, causing it to deviate from its intended relative positional encoding, especially in long-context scenarios. This issue arises from BFloat16's limited precision and accumulates as context length increases, with the first token contributing significantly to this problem. To address this, we develop AnchorAttention, a plug-and-play attention method that alleviates numerical issues caused by BFloat16, improves long-context capabilities, and speeds up training. AnchorAttention reduces unnecessary attention computations, maintains semantic coherence, and boosts computational efficiency by treating the first token as a shared anchor with a consistent position ID, making it visible to all documents within the training context. Experiments on three types of LLMs demonstrate that AnchorAttention significantly improves long-context performance and reduces training time by over 50\\% compared to standard full attention mechanisms, while preserving the original LLM's capabilities on general tasks. Our code is available at https://github.com/haonan3/AnchorContext.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Wang","given":"Haonan"},{"family":"Liu","given":"Qian"},{"family":"Du","given":"Chao"},{"family":"Zhu","given":"Tongyao"},{"family":"Du","given":"Cunxiao"},{"family":"Kawaguchi","given":"Kenji"},{"family":"Pang","given":"Tianyu"}],"citation-key":"wangWhenPrecisionMeets2024","DOI":"10.48550/arXiv.2411.13476","issued":{"date-parts":[["2024",11,26]]},"number":"arXiv:2411.13476","publisher":"arXiv","source":"arXiv.org","title":"When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training","title-short":"When Precision Meets Position","type":"article","URL":"http://arxiv.org/abs/2411.13476"},
  {"id":"warnerSmarterBetterFaster2024","abstract":"Encoder-only transformer models such as BERT offer a great performance-size tradeoff for retrieval and classification tasks with respect to larger decoder-only models. Despite being the workhorse of numerous production pipelines, there have been limited Pareto improvements to BERT since its release. In this paper, we introduce ModernBERT, bringing modern model optimizations to encoder-only models and representing a major Pareto improvement over older encoders. Trained on 2 trillion tokens with a native 8192 sequence length, ModernBERT models exhibit state-of-the-art results on a large pool of evaluations encompassing diverse classification tasks and both single and multi-vector retrieval on different domains (including code). In addition to strong downstream performance, ModernBERT is also the most speed and memory efficient encoder and is designed for inference on common GPUs.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Warner","given":"Benjamin"},{"family":"Chaffin","given":"Antoine"},{"family":"Clavié","given":"Benjamin"},{"family":"Weller","given":"Orion"},{"family":"Hallström","given":"Oskar"},{"family":"Taghadouini","given":"Said"},{"family":"Gallagher","given":"Alexis"},{"family":"Biswas","given":"Raja"},{"family":"Ladhak","given":"Faisal"},{"family":"Aarsen","given":"Tom"},{"family":"Cooper","given":"Nathan"},{"family":"Adams","given":"Griffin"},{"family":"Howard","given":"Jeremy"},{"family":"Poli","given":"Iacopo"}],"citation-key":"warnerSmarterBetterFaster2024","DOI":"10.48550/arXiv.2412.13663","issued":{"date-parts":[["2024",12,19]]},"number":"arXiv:2412.13663","publisher":"arXiv","source":"arXiv.org","title":"Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference","title-short":"Smarter, Better, Faster, Longer","type":"article","URL":"http://arxiv.org/abs/2412.13663"},
  {"id":"weiChainofThoughtPromptingElicits2023","abstract":"We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Wei","given":"Jason"},{"family":"Wang","given":"Xuezhi"},{"family":"Schuurmans","given":"Dale"},{"family":"Bosma","given":"Maarten"},{"family":"Ichter","given":"Brian"},{"family":"Xia","given":"Fei"},{"family":"Chi","given":"Ed"},{"family":"Le","given":"Quoc"},{"family":"Zhou","given":"Denny"}],"citation-key":"weiChainofThoughtPromptingElicits2023","DOI":"10.48550/arXiv.2201.11903","issued":{"date-parts":[["2023",1,10]]},"number":"arXiv:2201.11903","publisher":"arXiv","source":"arXiv.org","title":"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","type":"article","URL":"http://arxiv.org/abs/2201.11903"},
  {"id":"wijmansCutYourLosses2024","abstract":"As language models grow ever larger, so do their vocabularies. This has shifted the memory footprint of LLMs during training disproportionately to one single layer: the cross-entropy in the loss computation. Cross-entropy builds up a logit matrix with entries for each pair of input tokens and vocabulary items and, for small models, consumes an order of magnitude more memory than the rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that computes the cross-entropy loss without materializing the logits for all tokens into global memory. Rather, CCE only computes the logit for the correct token and evaluates the log-sum-exp over all logits on the fly. We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible. This has a dramatic effect. Taking the Gemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss computation from 24 GB to 1 MB, and the total training-time memory consumption of the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we leverage the inherent sparsity of softmax and propose to skip elements of the gradient computation that have a negligible (i.e., below numerical precision) contribution to the gradient. Experiments demonstrate that the dramatic reduction in memory consumption is accomplished without sacrificing training speed or convergence.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Wijmans","given":"Erik"},{"family":"Huval","given":"Brody"},{"family":"Hertzberg","given":"Alexander"},{"family":"Koltun","given":"Vladlen"},{"family":"Krähenbühl","given":"Philipp"}],"citation-key":"wijmansCutYourLosses2024","DOI":"10.48550/arXiv.2411.09009","issued":{"date-parts":[["2024",11,13]]},"number":"arXiv:2411.09009","publisher":"arXiv","source":"arXiv.org","title":"Cut Your Losses in Large-Vocabulary Language Models","type":"article","URL":"http://arxiv.org/abs/2411.09009"},
  {"id":"wuSCOPEOptimizingKeyValue2024","abstract":"Key-Value (KV) cache has become a bottleneck of LLMs for long-context generation. Despite the numerous efforts in this area, the optimization for the decoding phase is generally ignored. However, we believe such optimization is crucial, especially for long-output generation tasks based on the following two observations: (i) Excessive compression during the prefill phase, which requires specific full context impairs the comprehension of the reasoning task; (ii) Deviation of heavy hitters occurs in the reasoning tasks with long outputs. Therefore, SCOPE, a simple yet efficient framework that separately performs KV cache optimization during the prefill and decoding phases, is introduced. Specifically, the KV cache during the prefill phase is preserved to maintain the essential information, while a novel strategy based on sliding is proposed to select essential heavy hitters for the decoding phase. Memory usage and memory transfer are further optimized using adaptive and discontinuous strategies. Extensive experiments on LongGenBench show the effectiveness and generalization of SCOPE and its compatibility as a plug-in to other prefill-only KV compression methods.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Wu","given":"Jialong"},{"family":"Wang","given":"Zhenglin"},{"family":"Zhang","given":"Linhai"},{"family":"Lai","given":"Yilong"},{"family":"He","given":"Yulan"},{"family":"Zhou","given":"Deyu"}],"citation-key":"wuSCOPEOptimizingKeyValue2024","DOI":"10.48550/arXiv.2412.13649","issued":{"date-parts":[["2024",12,18]]},"number":"arXiv:2412.13649","publisher":"arXiv","source":"arXiv.org","title":"SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation","title-short":"SCOPE","type":"article","URL":"http://arxiv.org/abs/2412.13649"},
  {"id":"xuDPOSuperiorPPO2024","abstract":"Reinforcement Learning from Human Feedback (RLHF) is currently the most widely used method to align large language models (LLMs) with human preferences. Existing RLHF methods can be roughly categorized as either reward-based or reward-free. Novel applications such as ChatGPT and Claude leverage reward-based methods that first learn a reward model and apply actor-critic algorithms, such as Proximal Policy Optimization (PPO). However, in academic benchmarks, state-of-the-art results are often achieved via reward-free methods, such as Direct Preference Optimization (DPO). Is DPO truly superior to PPO? Why does PPO perform poorly on these benchmarks? In this paper, we first conduct both theoretical and empirical studies on the algorithmic properties of DPO and show that DPO may have fundamental limitations. Moreover, we also comprehensively examine PPO and reveal the key factors for the best performances of PPO in fine-tuning LLMs. Finally, we benchmark DPO and PPO across a collection of RLHF testbeds, ranging from dialogue to code generation. Experiment results demonstrate that PPO is able to surpass other alignment methods in all cases and achieve state-of-the-art results in challenging code competitions. Our code is publicly available at https://github.com/openpsi-project/ReaLHF.","accessed":{"date-parts":[["2025",1,2]]},"author":[{"family":"Xu","given":"Shusheng"},{"family":"Fu","given":"Wei"},{"family":"Gao","given":"Jiaxuan"},{"family":"Ye","given":"Wenjie"},{"family":"Liu","given":"Weilin"},{"family":"Mei","given":"Zhiyu"},{"family":"Wang","given":"Guangju"},{"family":"Yu","given":"Chao"},{"family":"Wu","given":"Yi"}],"citation-key":"xuDPOSuperiorPPO2024","DOI":"10.48550/arXiv.2404.10719","issued":{"date-parts":[["2024",10,10]]},"number":"arXiv:2404.10719","publisher":"arXiv","source":"arXiv.org","title":"Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study","title-short":"Is DPO Superior to PPO for LLM Alignment?","type":"article","URL":"http://arxiv.org/abs/2404.10719"},
  {"id":"zengScalingSearchLearning2024","abstract":"OpenAI o1 represents a significant milestone in Artificial Inteiligence, which achieves expert-level performances on many challanging tasks that require strong reasoning ability.OpenAI has claimed that the main techinique behinds o1 is the reinforcement learining. Recent works use alternative approaches like knowledge distillation to imitate o1's reasoning style, but their effectiveness is limited by the capability ceiling of the teacher model. Therefore, this paper analyzes the roadmap to achieving o1 from the perspective of reinforcement learning, focusing on four key components: policy initialization, reward design, search, and learning. Policy initialization enables models to develop human-like reasoning behaviors, equipping them with the ability to effectively explore solution spaces for complex problems. Reward design provides dense and effective signals via reward shaping or reward modeling, which is the guidance for both search and learning. Search plays a crucial role in generating high-quality solutions during both training and testing phases, which can produce better solutions with more computation. Learning utilizes the data generated by search for improving policy, which can achieve the better performance with more parameters and more searched data. Existing open-source projects that attempt to reproduce o1 can be seem as a part or a variant of our roadmap. Collectively, these components underscore how learning and search drive o1's advancement, making meaningful contributions to the development of LLM.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Zeng","given":"Zhiyuan"},{"family":"Cheng","given":"Qinyuan"},{"family":"Yin","given":"Zhangyue"},{"family":"Wang","given":"Bo"},{"family":"Li","given":"Shimin"},{"family":"Zhou","given":"Yunhua"},{"family":"Guo","given":"Qipeng"},{"family":"Huang","given":"Xuanjing"},{"family":"Qiu","given":"Xipeng"}],"citation-key":"zengScalingSearchLearning2024","DOI":"10.48550/arXiv.2412.14135","issued":{"date-parts":[["2024",12,18]]},"number":"arXiv:2412.14135","publisher":"arXiv","source":"arXiv.org","title":"Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective","title-short":"Scaling of Search and Learning","type":"article","URL":"http://arxiv.org/abs/2412.14135"},
  {"id":"zhengAttentionHeadsLarge2024","abstract":"Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in various tasks but remain as black-box systems. Understanding the reasoning bottlenecks of LLMs has become a critical challenge, as these limitations are deeply tied to their internal architecture. Among these, attention heads have emerged as a focal point for investigating the underlying mechanics of LLMs. In this survey, we aim to demystify the internal reasoning processes of LLMs by systematically exploring the roles and mechanisms of attention heads. We first introduce a novel four-stage framework inspired by the human thought process: Knowledge Recalling, In-Context Identification, Latent Reasoning, and Expression Preparation. Using this framework, we comprehensively review existing research to identify and categorize the functions of specific attention heads. Additionally, we analyze the experimental methodologies used to discover these special heads, dividing them into two categories: Modeling-Free and Modeling-Required methods. We further summarize relevant evaluation methods and benchmarks. Finally, we discuss the limitations of current research and propose several potential future directions.","accessed":{"date-parts":[["2025",1,3]]},"author":[{"family":"Zheng","given":"Zifan"},{"family":"Wang","given":"Yezhaohui"},{"family":"Huang","given":"Yuxin"},{"family":"Song","given":"Shichao"},{"family":"Yang","given":"Mingchuan"},{"family":"Tang","given":"Bo"},{"family":"Xiong","given":"Feiyu"},{"family":"Li","given":"Zhiyu"}],"citation-key":"zhengAttentionHeadsLarge2024","DOI":"10.48550/arXiv.2409.03752","issued":{"date-parts":[["2024",12,23]]},"number":"arXiv:2409.03752","publisher":"arXiv","source":"arXiv.org","title":"Attention Heads of Large Language Models: A Survey","title-short":"Attention Heads of Large Language Models","type":"article","URL":"http://arxiv.org/abs/2409.03752"}
]
